---
# Source: nemo-microservices-helm-chart/charts/core/charts/postgresql/templates/primary/networkpolicy.yaml
kind: NetworkPolicy
apiVersion: networking.k8s.io/v1
metadata:
  name: nemo-jobsdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.2.4
    app.kubernetes.io/component: primary
spec:
  podSelector:
    matchLabels:
      app.kubernetes.io/instance: nemo
      app.kubernetes.io/name: jobsdb
      app.kubernetes.io/component: primary
  policyTypes:
    - Ingress
    - Egress
  egress:
    - {}
  ingress:
    - ports:
        - port: 5432
---
# Source: nemo-microservices-helm-chart/charts/core/charts/postgresql/templates/primary/pdb.yaml
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: nemo-jobsdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.2.4
    app.kubernetes.io/component: primary
spec:
  maxUnavailable: 1
  selector:
    matchLabels:
      app.kubernetes.io/instance: nemo
      app.kubernetes.io/name: jobsdb
      app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/core/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: jobs-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.2.4
automountServiceAccountToken: false
---
# Source: nemo-microservices-helm-chart/charts/core/templates/api-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-core-api
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/core/templates/controller-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-core-controller
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/core/templates/logcollector-serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-core-logcollector
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/opentelemetry-collector/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-opentelemetry-collector
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.93.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "0.102.1"
    app.kubernetes.io/managed-by: Helm
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: customizer-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: customizerdb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
automountServiceAccountToken: false
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/service-account.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-customizer
  namespace: default
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/data-designer/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-data-designer
  labels:
    app.kubernetes.io/name: data-designer
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-designer-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/data-store/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
automountServiceAccountToken: false
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/gitea/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: gitea
  namespace: "default"
  labels:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app: data-store
    version: "25.12"
automountServiceAccountToken: false
imagePullSecrets:
  - name: nvcrimagepullsecret
---
# Source: nemo-microservices-helm-chart/charts/deployment-management/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-deployment-management
  labels:
    app.kubernetes.io/name: deployment-management
    app.kubernetes.io/instance: nemo
    helm.sh/chart: deployment-management-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/entity-store/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: entity-store-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: entity-storedb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
automountServiceAccountToken: false
---
# Source: nemo-microservices-helm-chart/charts/evaluator/charts/postgresql/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: evaluator-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: evaluatordb
    app.kubernetes.io/version: 16.2.0
    helm.sh/chart: postgresql-14.0.4
automountServiceAccountToken: false
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-evaluator
  labels:
    app.kubernetes.io/name: evaluator
    app.kubernetes.io/instance: nemo
    helm.sh/chart: evaluator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-nemo-operator-controller-manager
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
  annotations:
    {}
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: k8s-nim-operator
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: k8s-nim-operator
    app.kubernetes.io/part-of: k8s-nim-operator
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
---
# Source: nemo-microservices-helm-chart/charts/nim-proxy/templates/serviceaccount.yaml
apiVersion: v1
kind: ServiceAccount
metadata:
  name: nemo-nim-proxy
  labels:
    app.kubernetes.io/name: nim-proxy
    app.kubernetes.io/instance: nemo
    helm.sh/chart: nim-proxy-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
automountServiceAccountToken: true
---
# Source: nemo-microservices-helm-chart/charts/core/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-jobsdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.2.4
type: Opaque
data:
  postgres-password: "bmVtbw=="
  password: "bmVtbw=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: nemo-microservices-helm-chart/charts/core/templates/models-database-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-core-models-db-secret
  labels:
    app.kubernetes.io/component: nemo-core-models-db
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  password: "pass"
---
# Source: nemo-microservices-helm-chart/charts/core/templates/models-datastore-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-models-datastore-token
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
type: Opaque
stringData:
  HF_TOKEN: ""
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-customizerdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: customizerdb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
type: Opaque
data:
  postgres-password: "WmJDTTFxZTNaVg=="
  password: "bmVtbw=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/wandb-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: wandb-secret
type: Opaque
data:
  encryption_key: "ZWM2MGQ5NmI2Mzk3NjRjY2Y5ODU5YmMxMGQ0MzYzZDE="
---
# Source: nemo-microservices-helm-chart/charts/data-store/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
type: Opaque
data:
  postgres-password: "ZzNTNVdzcDFJUw=="
  password: "ZGF0YXN0b3Jl"
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/datastore/external-object-store-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-data-store-external-objstore
type: Opaque
data:
  accessKey: ""
  accessSecret: ""
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/datastore/lfs-jwt-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-data-store--lfs-jwt
type: Opaque
data:
  jwtSecret: "WkRkaWVHdFpObmRITUV0WVNreEtZbmxDVG5ocmRqTkNhMmRZVUVkRFNHaw=="
---
# Source: nemo-microservices-helm-chart/charts/deployment-management/templates/datastore-api-secret.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-deployment-management-service-ds-hf-token
  labels:
    app.kubernetes.io/name: deployment-management
    app.kubernetes.io/instance: nemo
    helm.sh/chart: deployment-management-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
type: Opaque
data:
  HF_TOKEN:
---
# Source: nemo-microservices-helm-chart/charts/entity-store/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-entity-storedb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: entity-storedb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
type: Opaque
data:
  postgres-password: "Zlo1ZndFenZ1eQ=="
  password: "cGFzcw=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: nemo-microservices-helm-chart/charts/evaluator/charts/postgresql/templates/secrets.yaml
apiVersion: v1
kind: Secret
metadata:
  name: nemo-evaluatordb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: evaluatordb
    app.kubernetes.io/version: 16.2.0
    helm.sh/chart: postgresql-14.0.4
type: Opaque
data:
  postgres-password: "RXBNUUV3cmxEZg=="
  password: "bmVtbw=="
  # We don't auto-generate LDAP password when it's not provided as we do for other passwords
---
# Source: nemo-microservices-helm-chart/charts/core/templates/logcollector-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-core-jobs-logcollector
data:
  fluent-bit.yaml: |
    service:
      flush: 1
      http_server: on
      health_check: on

    parsers:
      - name: json
        format: json
      - name: docker
        format: json
        time_key: time
        time_format: "%Y-%m-%dT%H:%M:%S.%L"
        time_keep: true

    pipeline:
      inputs:
        - name: opentelemetry
          listen: 0.0.0.0
          port: 4318

      filters:
        - name: lua
          match: '*'
          call: cb_nemo_otel_collector
          code: |
            function cb_nemo_otel_collector(tag, timestamp, group, metadata, record)
              record.job_id = group.resource.attributes.job_id or 'unknown'
              record.job_step = group.resource.attributes.job_step or 'unknown'
              record.job_task = group.resource.attributes.job_task or 'unknown'
              return 1, timestamp, metadata, record
            end

      outputs:
        - name: pgsql
          match: '*'
          Host:         ${DB_HOST}
          Port:         ${DB_PORT}
          User:         ${DB_USER}
          Password:     ${DB_PASS}
          Database:     ${DB_NAME}
          Table:        platformjoblogfluentbitlanding
          # Use the Fluent Bit internal timestamp for the 'time' column
          Timestamp_Key: '@timestamp'
---
# Source: nemo-microservices-helm-chart/charts/core/templates/logsidecar-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-core-jobs-logsidecar
data:
  fluent-bit.yaml: |
    service:
      flush: 1
      grace: 15
      http_server: on
      health_check: on
      storage.backlog.flush_on_shutdown: on

    pipeline:
      inputs:
        - name: tail
          tag: '*'
          # The log path follows the standard convention for Kubernetes logs on the host
          # The NEMO_JOB_TASK is the pod uid.
          path: '${NEMO_JOB_LOG_PATH}/*.log'
          multiline.parser: docker, cri
          mem_buf_limit: '100MB'
          skip_long_lines: On
          refresh_interval: 1
          inotify_watcher: false

          processors:
            logs:
              - name: opentelemetry_envelope
              - name: content_modifier
                context: otel_resource_attributes
                action: upsert
                key: service.name
                value: nemo

              - name: content_modifier
                context: otel_resource_attributes
                action: upsert
                key: job_id
                value: ${NEMO_JOB_ID}

              - name: content_modifier
                context: otel_resource_attributes
                action: upsert
                key: job_step
                value: ${NEMO_JOB_STEP}

              - name: content_modifier
                context: otel_resource_attributes
                action: upsert
                key: job_task
                value: ${NEMO_JOB_TASK}

      outputs:
        - name: opentelemetry
          match: '*'
          host: nemo-core-jobs-logcollector
          port: 4318
          logs_uri:      /v1/logs
          logs_body_key: log
          logs_attributes_metadata_key: attrs
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/opentelemetry-collector/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-opentelemetry-collector
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.93.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "0.102.1"
    app.kubernetes.io/managed-by: Helm
    
data:
  relay: |
    exporters:
      debug:
        verbosity: detailed
    extensions:
      health_check:
        endpoint: ${env:MY_POD_IP}:13133
      zpages:
        endpoint: 0.0.0.0:55679
    processors:
      batch: {}
      memory_limiter:
        check_interval: 5s
        limit_percentage: 80
        spike_limit_percentage: 25
    receivers:
      jaeger:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:14250
          thrift_compact:
            endpoint: ${env:MY_POD_IP}:6831
          thrift_http:
            endpoint: ${env:MY_POD_IP}:14268
      otlp:
        protocols:
          grpc:
            endpoint: ${env:MY_POD_IP}:4317
          http:
            cors:
              allowed_origins:
              - '*'
            endpoint: ${env:MY_POD_IP}:4318
      prometheus:
        config:
          scrape_configs:
          - job_name: opentelemetry-collector
            scrape_interval: 10s
            static_configs:
            - targets:
              - ${env:MY_POD_IP}:8888
      zipkin:
        endpoint: ${env:MY_POD_IP}:9411
    service:
      extensions:
      - zpages
      - health_check
      pipelines:
        logs:
          exporters:
          - debug
          processors:
          - batch
          receivers:
          - otlp
        metrics:
          exporters:
          - debug
          processors:
          - batch
          receivers:
          - otlp
        traces:
          exporters:
          - debug
          processors:
          - batch
          receivers:
          - otlp
      telemetry:
        metrics:
          address: ${env:MY_POD_IP}:8888
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-customizer-config
data:
    config.yaml: |-
      namespace: default
      entity_store_url: http://nemo-entity-store:8000
      nemo_data_store_url: http://nemo-data-store:3000
      mlflow_tracking_url: ""

      wandb:
        entity: null
        project: nvidia-nemo-customizer

      training:
        queue: "default"
        image: "nvcr.io/nvidia/nemo-microservices/customizer:25.12"
        automodelImage: "nvcr.io/nvidia/nemo-microservices/customizer-automodel:25.12"
        nemoRlImage: "nvcr.io/nvidia/nemo-microservices/customizer-rl:25.12"  
        imagePullSecrets:
          - name: nvcrimagepullsecret
        pvc:
          size: 5Gi
          volumeAccessMode: ReadWriteOnce
          name: null
        env:
          - name: LOG_LEVEL
            value: INFO

        workspace_dir: /pvc/workspace
        # volumes reference pre-existing PVCs
        volumes:
          # Model cache PVC
          - name: models
            persistentVolumeClaim:
              claimName: finetuning-ms-models-pvc
              readOnly: True
          - name: dshm
            emptyDir:
              medium: Memory
        volumeMounts:
          - name: models
            mountPath: "/mount/models"
            readOnly: True
          - name: dshm
            mountPath: "/dev/shm"

        # Network configuration for multi node training specific to CSP
        training_networking:
          - name: "NCCL_IB_SL"
            value: 0
          - name: "NCCL_IB_TC"
            value: 41
          - name: "NCCL_IB_QPS_PER_CONNECTION"
            value: 4
          - name: "UCX_TLS"
            value: TCP
          - name: "UCX_NET_DEVICES"
            value: eth0
          - name: "HCOLL_ENABLE_MCAST_ALL"
            value: 0
          - name: "NCCL_IB_GID_INDEX"
            value: 3
        poll_interval_seconds: 10
        ttl_seconds_after_finished: 3600

        tolerations:
            []
        nodeSelectors:
            {}

        container_defaults:
            imagePullPolicy: IfNotPresent
            securityContext:
              fsGroup: 1000
              runAsGroup: 1000
              runAsNonRoot: true
              runAsUser: 1000

        use_run_ai_executor: false

      model_download_jobs:
        image: "nvcr.io/nvidia/nemo-microservices/customizer-api:25.12"
        imagePullPolicy: IfNotPresent
        imagePullSecrets:
          - name: nvcrimagepullsecret
        ngcSecretName: ngc-api
        ngcSecretKey: NGC_API_KEY
        hfSecretName: null
        hfSecretKey: HF_TOKEN
        securityContext:
            fsGroup: 1000
            runAsGroup: 1000
            runAsNonRoot: true
            runAsUser: 1000
        ttlSecondsAfterFinished: 1800

      nemo_data_store_tools:
        image: nvcr.io/nvidia/nemo-microservices/nds-v2-huggingface-cli:25.12
        imagePullSecret: nvcrimagepullsecret

      customizationTargets:
            hfTargetDownload:
              allowedHfOrgs: []
              enabled: false
            overrideExistingTargets: true
            targets:
              meta/llama-3.1-8b-instruct@2.0:
                base_model: meta/llama-3.1-8b-instruct
                enabled: true
                model_path: llama-3_1-8b-instruct_2_0
                model_uri: ngc://nvidia/nemo/llama-3_1-8b-instruct-nemo:2.0
                name: llama-3.1-8b-instruct@2.0
                namespace: meta
                num_parameters: 8000000000
                precision: bf16-mixed
              meta/llama-3.1-70b-instruct@2.0:
                base_model: meta/llama-3.1-70b-instruct
                enabled: false
                model_path: llama-3_1-70b-instruct_2_0
                model_uri: ngc://nvidia/nemo/llama-3_1-70b-instruct-nemo:2.0
                name: llama-3.1-70b-instruct@2.0
                namespace: meta
                num_parameters: 70000000000
                precision: bf16-mixed
              meta/llama-3.2-1b-instruct@2.0:
                base_model: meta/llama-3.2-1b-instruct
                enabled: true
                model_path: llama32_1b-instruct_2_0
                model_uri: ngc://nvidia/nemo/llama-3_2-1b-instruct:2.0
                name: llama-3.2-1b-instruct@2.0
                namespace: meta
                num_parameters: 1000000000
                precision: bf16-mixed
              meta/llama-3.2-1b@2.0:
                base_model: meta/llama-3.2-1b
                enabled: false
                model_path: llama32_1b_2_0
                model_uri: ngc://nvidia/nemo/llama-3_2-1b:2.0
                name: llama-3.2-1b@2.0
                namespace: meta
                num_parameters: 1000000000
                precision: bf16-mixed
              meta/llama-3.2-3b-instruct@2.0:
                base_model: meta/llama-3.2-3b-instruct
                enabled: false
                model_path: llama32_3b-instruct_2_0
                model_uri: ngc://nvidia/nemo/llama-3_2-3b-instruct:2.0
                name: llama-3.2-3b-instruct@2.0
                namespace: meta
                num_parameters: 3000000000
                precision: bf16-mixed
              meta/llama-3.3-70b-instruct@2.0:
                base_model: meta/llama-3.3-70b-instruct
                enabled: false
                model_path: llama-3_3-70b-instruct_2_0
                model_uri: ngc://nvidia/nemo/llama-3_3-70b-instruct:2.0
                name: llama-3.3-70b-instruct@2.0
                namespace: meta
                num_parameters: 70000000000
                precision: bf16-mixed
              meta/llama3-70b-instruct@2.0:
                base_model: meta/llama3-70b-instruct
                enabled: false
                model_path: llama-3-70b-bf16_2_0
                model_uri: ngc://nvidia/nemo/llama-3-70b-instruct-nemo:2.0
                name: llama3-70b-instruct@2.0
                namespace: meta
                num_parameters: 70000000000
                precision: bf16-mixed
              microsoft/phi-4@1.0:
                base_model: microsoft/phi-4
                enabled: false
                model_path: phi-4_1_0
                model_uri: ngc://nvidia/nemo/phi-4:1.0
                name: phi-4@1.0
                namespace: microsoft
                num_parameters: 14659507200
                precision: bf16
                version: "1.0"
              mistralai/ministral-3-3B-reasoning-2512@v1:
                base_model: mistralai/Ministral-3-3B-Reasoning-2512
                enabled: false
                hf_endpoint: https://huggingface.co
                model_path: mistral-3-3b-reasoning-2512
                model_uri: hf://mistralai/Ministral-3-3B-Reasoning-2512
                name: ministral-3-3B-reasoning-2512@v1
                namespace: mistralai
                num_parameters: 3400000000
                precision: bf16-mixed
              nvidia/llama-3.2-nv-embedqa-1b@v2:
                base_model: nvidia/llama-3.2-nv-embedqa-1b-v2
                enabled: false
                model_path: llama32_1b-embedding
                model_uri: ngc://nvidia/nemo/llama-3_2-1b-embedding-base:0.0.1
                name: llama-3.2-nv-embedqa-1b@v2
                namespace: nvidia
                num_parameters: 1000000000
                precision: bf16-mixed
              nvidia/nemotron-nano-9b-v2@v1:
                base_model: nvidia/nemotron-nano-9b-v2
                enabled: false
                hf_endpoint: https://huggingface.co
                model_path: nemotron_nano_9b_v2
                model_uri: hf://nvidia/NVIDIA-Nemotron-Nano-9B-v2
                name: nemotron-nano-9b-v2@v1
                namespace: nvidia
                num_parameters: 9000000000
                precision: bf16-mixed
              nvidia/nemotron-nano-llama-3.1-8b@1.0:
                base_model: nvidia/llama-3.1-nemotron-nano-8b-v1
                enabled: false
                model_path: nemotron-nano-3_1-8b_0_0_1
                model_uri: ngc://nvidia/nemo/nemotron-nano-3_1-8b:0.0.1
                name: nemotron-nano-llama-3.1-8b@1.0
                namespace: nvidia
                num_parameters: 8000000000
                precision: bf16-mixed
              nvidia/nemotron-super-llama-3.3-49b@1.0:
                base_model: nvidia/llama-3.3-nemotron-super-49b-v1
                enabled: false
                model_path: nemotron-super-3_3-49b_v1
                model_uri: ngc://nvidia/nemo/nemotron-super-3_3-49b:v1
                name: nemotron-super-llama-3.3-49b@1.0
                namespace: nvidia
                num_parameters: 4900000000
                precision: bf16-mixed
              nvidia/nemotron-super-llama-3.3-49b@1.5:
                base_model: nvidia/llama-3.3-nemotron-super-49b-v1.5
                enabled: false
                hf_endpoint: https://huggingface.co
                model_path: nemotron-super-3_3-49b_v1_5
                model_uri: hf://nvidia/Llama-3_3-Nemotron-Super-49B-v1_5
                name: nemotron-super-llama-3.3-49b@1.5
                namespace: nvidia
                num_parameters: 4900000000
                precision: bf16-mixed
              openai/gpt-oss-20b@v1:
                base_model: openai/gpt-oss-20b
                enabled: false
                hf_endpoint: https://huggingface.co
                model_path: gpt_oss_20b
                model_uri: hf://openai/gpt-oss-20b
                name: gpt-oss-20b@v1
                namespace: openai
                num_parameters: 21000000000
                precision: bf16-mixed
            trustedModelURIs:
            - hf://nvidia/Llama-3_3-Nemotron-Super-49B-v1_5
            - hf://nvidia/Llama-3_3-Nemotron-Super-49B-v1
            - hf://nvidia/NVIDIA-Nemotron-Nano-9B-v2
            - hf://nvidia/NVIDIA-Nemotron-Nano-12B-v2
            - hf://nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16

      customizationConfigTemplates:
            overrideExistingTemplates: true
            templates:
              meta/llama-3.1-8b-instruct@v1.0.0+40GB:
                max_seq_length: 4096
                name: llama-3.1-8b-instruct@v1.0.0+40GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.1-8b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 2
                  tensor_parallel_size: 2
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 2
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 2
                  tensor_parallel_size: 8
                  training_type: dpo
              meta/llama-3.1-8b-instruct@v1.0.0+80GB:
                max_seq_length: 4096
                name: llama-3.1-8b-instruct@v1.0.0+80GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.1-8b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 8
                  num_nodes: 1
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 8
                  num_nodes: 1
                  tensor_parallel_size: 8
                  training_type: dpo
              meta/llama-3.1-70b-instruct@v1.0.0+40GB:
                max_seq_length: 4096
                name: llama-3.1-70b-instruct@v1.0.0+40GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.1-70b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 2
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
              meta/llama-3.1-70b-instruct@v1.0.0+80GB:
                max_seq_length: 4096
                name: llama-3.1-70b-instruct@v1.0.0+80GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.1-70b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 1
                  tensor_parallel_size: 4
                  training_type: sft
              meta/llama-3.2-1b-instruct@v1.0.0+40GB:
                max_seq_length: 4096
                name: llama-3.2-1b-instruct@v1.0.0+40GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.2-1b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 2
                  num_nodes: 1
                  tensor_parallel_size: 2
                  training_type: dpo
              meta/llama-3.2-1b-instruct@v1.0.0+80GB:
                max_seq_length: 4096
                name: llama-3.2-1b-instruct@v1.0.0+80GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.2-1b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: dpo
              meta/llama-3.2-1b@v1.0.0+40GB:
                max_seq_length: 4096
                name: llama-3.2-1b@v1.0.0+40GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.2-1b@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              meta/llama-3.2-1b@v1.0.0+80GB:
                max_seq_length: 4096
                name: llama-3.2-1b@v1.0.0+80GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.2-1b@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              meta/llama-3.2-3b-instruct@v1.0.0+40GB:
                max_seq_length: 4096
                name: llama-3.2-3b-instruct@v1.0.0+40GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.2-3b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              meta/llama-3.2-3b-instruct@v1.0.0+80GB:
                max_seq_length: 4096
                name: llama-3.2-3b-instruct@v1.0.0+80GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.2-3b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              meta/llama-3.3-70b-instruct@v1.0.0+40GB:
                max_seq_length: 4096
                name: llama-3.3-70b-instruct@v1.0.0+40GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.3-70b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 2
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
              meta/llama-3.3-70b-instruct@v1.0.0+80GB:
                max_seq_length: 4096
                name: llama-3.3-70b-instruct@v1.0.0+80GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama-3.3-70b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 1
                  tensor_parallel_size: 4
                  training_type: sft
              meta/llama3-70b-instruct@v1.0.0+40GB:
                max_seq_length: 4096
                name: llama3-70b-instruct@v1.0.0+40GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama3-70b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 2
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
              meta/llama3-70b-instruct@v1.0.0+80GB:
                max_seq_length: 4096
                name: llama3-70b-instruct@v1.0.0+80GB
                namespace: meta
                prompt_template: '{prompt} {completion}'
                target: meta/llama3-70b-instruct@2.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 1
                  tensor_parallel_size: 4
                  training_type: sft
              microsoft/phi-4@v1.0.0+40GB:
                max_seq_length: 4096
                name: phi-4@v1.0.0+40GB
                namespace: microsoft
                prompt_template: '{prompt} {completion}'
                target: microsoft/phi-4@1.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 2
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              microsoft/phi-4@v1.0.0+80GB:
                max_seq_length: 4096
                name: phi-4@v1.0.0+80GB
                namespace: microsoft
                prompt_template: '{prompt} {completion}'
                target: microsoft/phi-4@1.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  training_type: sft
              mistralai/ministral-3-3B-reasoning-2512@v1.0.0+80GB:
                max_seq_length: 4096
                name: ministral-3-3B-reasoning-2512@v1.0.0+80GB
                namespace: mistralai
                prompt_template: '{prompt} {completion}'
                target: mistralai/ministral-3-3B-reasoning-2512@v1
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              nvidia/llama-3.2-nv-embedqa-1b@v2+40GB:
                max_seq_length: 2048
                name: llama-3.2-nv-embedqa-1b@v2+40GB
                namespace: nvidia
                target: nvidia/llama-3.2-nv-embedqa-1b@v2
                training_options:
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              nvidia/llama-3.2-nv-embedqa-1b@v2+80GB:
                max_seq_length: 2048
                name: llama-3.2-nv-embedqa-1b@v2+80GB
                namespace: nvidia
                prompt_template: '{prompt} {completion}'
                target: nvidia/llama-3.2-nv-embedqa-1b@v2
                training_options:
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: lora_merged
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
              nvidia/nemotron-nano-9b-v2@v1.0.0+80GB:
                max_seq_length: 4096
                name: nemotron-nano-9b-v2@v1.0.0+80GB
                namespace: nvidia
                prompt_template: '{prompt} {completion}'
                target: nvidia/nemotron-nano-9b-v2@v1
                training_options:
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 8
                  num_nodes: 1
                  pipeline_parallel_size: 1
                  tensor_parallel_size: 1
                  training_type: sft
              nvidia/nemotron-nano-llama-3.1-8b@v1.0.0+40GB:
                max_seq_length: 4096
                name: nemotron-nano-llama-3.1-8b@v1.0.0+40GB
                namespace: nvidia
                prompt_template: '{prompt} {completion}'
                target: nvidia/nemotron-nano-llama-3.1-8b@1.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 2
                  num_nodes: 1
                  tensor_parallel_size: 2
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 2
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
              nvidia/nemotron-nano-llama-3.1-8b@v1.0.0+80GB:
                max_seq_length: 4096
                name: nemotron-nano-llama-3.1-8b@v1.0.0+80GB
                namespace: nvidia
                prompt_template: '{prompt} {completion}'
                target: nvidia/nemotron-nano-llama-3.1-8b@1.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 8
                  num_nodes: 1
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
              nvidia/nemotron-super-llama-3.3-49b@v1.0.0+40GB:
                max_seq_length: 4096
                name: nemotron-super-llama-3.3-49b@v1.0.0+40GB
                namespace: nvidia
                prompt_template: '{prompt} {completion}'
                target: nvidia/nemotron-super-llama-3.3-49b@1.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 2
                  pipeline_parallel_size: 2
                  tensor_parallel_size: 4
                  training_type: sft
              nvidia/nemotron-super-llama-3.3-49b@v1.0.0+80GB:
                max_seq_length: 4096
                name: nemotron-super-llama-3.3-49b@v1.0.0+80GB
                namespace: nvidia
                prompt_template: '{prompt} {completion}'
                target: nvidia/nemotron-super-llama-3.3-49b@1.0
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 1
                  tensor_parallel_size: 4
                  training_type: sft
              nvidia/nemotron-super-llama-3.3-49b@v1.5+80GB:
                max_seq_length: 4096
                name: nemotron-super-llama-3.3-49b@v1.5+80GB
                namespace: nvidia
                prompt_template: '{prompt} {completion}'
                target: nvidia/nemotron-super-llama-3.3-49b@1.5
                training_options:
                - finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 4
                  num_nodes: 1
                  tensor_parallel_size: 4
                  training_type: sft
              openai/gpt-oss-20b@v1.0.0+80GB:
                max_seq_length: 4096
                name: gpt-oss-20b@v1.0.0+80GB
                namespace: openai
                prompt_template: '{prompt} {completion}'
                target: openai/gpt-oss-20b@v1
                training_options:
                - expert_model_parallel_size: 8
                  finetuning_type: all_weights
                  micro_batch_size: 1
                  num_gpus: 8
                  num_nodes: 1
                  pipeline_parallel_size: 1
                  tensor_parallel_size: 1
                  training_type: sft
                - expert_model_parallel_size: 1
                  finetuning_type: lora
                  micro_batch_size: 1
                  num_gpus: 1
                  num_nodes: 1
                  pipeline_parallel_size: 1
                  tensor_parallel_size: 1
                  training_type: sft
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/datastore/datastore-settings.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-data-store-setting
  labels:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app: data-store
    version: "25.12"
data:
  GITEA__LFS__SERVE_DIRECT: "true"
  GITEA__LFS__STORAGE_TYPE: "local"
  GITEA__SERVER__DOMAIN: "data-store.test"
  GITEA__SERVER__ROOT_URL: "http://data-store.test"
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/gitea/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-data-store-inline-config
  labels:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app: data-store
    version: "25.12"
data:
  _generals_: |-
    APP_NAME=Datastore
    RUN_MODE=prod
  cache: |-
    ADAPTER=memory
    HOST=
  cron.GIT_GC_REPOS: enabled=false
  database: |-
    DB_TYPE=postgres
    HOST=nemo-postgresql.default.svc.cluster.local:5432
    NAME=datastore
    PASSWD=datastore
    USER=datastore
  indexer: ISSUE_INDEXER_TYPE=db
  lfs: STORAGE_TYPE=local
  metrics: ENABLED=false
  queue: |-
    CONN_STR=
    TYPE=dummy
  repository: ROOT=/data/git/gitea-repositories
  security: INSTALL_LOCK=true
  server: |-
    APP_DATA_PATH=/data
    DOMAIN=nemo-data-store.default.svc.cluster.local
    ENABLE_PPROF=false
    HTTP_PORT=3000
    LFS_START_SERVER=true
    PROTOCOL=http
    ROOT_URL=http://nemo-data-store.default.svc.cluster.local
    SSH_DOMAIN=nemo-data-store.default.svc.cluster.local
    SSH_LISTEN_PORT=2222
    SSH_PORT=22
    START_SSH_SERVER=false
  session: |-
    PROVIDER=memory
    PROVIDER_CONFIG=
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/gitea/config.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-data-store
  labels:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app: data-store
    version: "25.12"
data:
  assertions: |
  config_environment.sh: |-
    #!/usr/bin/env bash
    set -euo pipefail

    function env2ini::log() {
      printf "${1}\n"
    }

    function env2ini::read_config_to_env() {
      local section="${1}"
      local line="${2}"

      if [[ -z "${line}" ]]; then
        # skip empty line
        return
      fi

      # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
      local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

      if [[ -z "${setting}" ]]; then
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      local value=''
      local regex="^${setting}(\s*)=(\s*)(.*)"
      if [[ $line =~ $regex ]]; then
        value="${BASH_REMATCH[3]}"
      else
        env2ini::log '  ! invalid setting'
        exit 1
      fi

      env2ini::log "    + '${setting}'"

      if [[ -z "${section}" ]]; then
        export "GITEA____${setting^^}=${value}"                           # '^^' makes the variable content uppercase
        return
      fi

      local masked_section="${section//./_0X2E_}"                            # '//' instructs to replace all matches
      masked_section="${masked_section//-/_0X2D_}"

      export "GITEA__${masked_section^^}__${setting^^}=${value}"        # '^^' makes the variable content uppercase
    }

    function env2ini::reload_preset_envs() {
      env2ini::log "Reloading preset envs..."

      while read -r line; do
        if [[ -z "${line}" ]]; then
          # skip empty line
          return
        fi

        # 'xargs echo -n' trims all leading/trailing whitespaces and a trailing new line
        local setting="$(awk -F '=' '{print $1}' <<< "${line}" | xargs echo -n)"

        if [[ -z "${setting}" ]]; then
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        local value=''
        local regex="^${setting}(\s*)=(\s*)(.*)"
        if [[ $line =~ $regex ]]; then
          value="${BASH_REMATCH[3]}"
        else
          env2ini::log '  ! invalid setting'
          exit 1
        fi

        env2ini::log "  + '${setting}'"

        export "${setting^^}=${value}"                           # '^^' makes the variable content uppercase
      done < "/tmp/existing-envs"

      rm /tmp/existing-envs
    }


    function env2ini::process_config_file() {
      local config_file="${1}"
      local section="$(basename "${config_file}")"

      if [[ $section == '_generals_' ]]; then
        env2ini::log "  [ini root]"
        section=''
      else
        env2ini::log "  ${section}"
      fi

      while read -r line; do
        env2ini::read_config_to_env "${section}" "${line}"
      done < <(awk 1 "${config_file}")                             # Helm .toYaml trims the trailing new line which breaks line processing; awk 1 ... adds it back while reading
    }

    function env2ini::load_config_sources() {
      local path="${1}"

      if [[ -d "${path}" ]]; then
        env2ini::log "Processing $(basename "${path}")..."

        while read -d '' configFile; do
          env2ini::process_config_file "${configFile}"
        done < <(find "${path}" -type l -not -name '..data' -print0)

        env2ini::log "\n"
      fi
    }

    function env2ini::generate_initial_secrets() {
      # These environment variables will either be
      #   - overwritten with user defined values,
      #   - initially used to set up Gitea
      # Anyway, they won't harm existing app.ini files

      export GITEA__SECURITY__INTERNAL_TOKEN=$(gitea generate secret INTERNAL_TOKEN)
      export GITEA__SECURITY__SECRET_KEY=$(gitea generate secret SECRET_KEY)
      export GITEA__OAUTH2__JWT_SECRET=$(gitea generate secret JWT_SECRET)
      export GITEA__SERVER__LFS_JWT_SECRET=$(gitea generate secret LFS_JWT_SECRET)

      env2ini::log "...Initial secrets generated\n"
    }

    # save existing envs prior to script execution. Necessary to keep order of preexisting and custom envs
    env | (grep -e '^GITEA__' || [[ $? == 1 ]]) > /tmp/existing-envs

    # MUST BE CALLED BEFORE OTHER CONFIGURATION
    env2ini::generate_initial_secrets

    env2ini::load_config_sources '/env-to-ini-mounts/inlines/'
    env2ini::load_config_sources '/env-to-ini-mounts/additionals/'

    # load existing envs to override auto generated envs
    env2ini::reload_preset_envs

    env2ini::log "=== All configuration sources loaded ===\n"

    # safety to prevent rewrite of secret keys if an app.ini already exists
    if [ -f ${GITEA_APP_INI} ]; then
      env2ini::log 'An app.ini file already exists. To prevent overwriting secret keys, these settings are dropped and remain unchanged:'
      env2ini::log '  - security.INTERNAL_TOKEN'
      env2ini::log '  - security.SECRET_KEY'
      env2ini::log '  - oauth2.JWT_SECRET'
      env2ini::log '  - server.LFS_JWT_SECRET'

      unset GITEA__SECURITY__INTERNAL_TOKEN
      unset GITEA__SECURITY__SECRET_KEY
      unset GITEA__OAUTH2__JWT_SECRET
      unset GITEA__SERVER__LFS_JWT_SECRET
    fi

    environment-to-ini -o $GITEA_APP_INI
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/gitea/init.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-data-store-init
  labels:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app: data-store
    version: "25.12"
data:
  configure_gpg_environment.sh: |-
    #!/usr/bin/env bash
    set -eu

    gpg --batch --import /raw/private.asc
  init_directory_structure.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    set -x
    mkdir -p /data/git/.ssh
    chmod -R 700 /data/git/.ssh
    [ ! -d /data/gitea/conf ] && mkdir -p /data/gitea/conf

    # prepare temp directory structure
    mkdir -p "${GITEA_TEMP}"
    chmod ug+rwx "${GITEA_TEMP}"

    

  configure_gitea.sh: |-
    #!/usr/bin/env bash

    set -euo pipefail

    echo '==== BEGIN DATASTORE CONFIGURATION ===='

    { # try
      gitea migrate
    } || { # catch
      echo "Gitea migrate might fail due to database connection...This init-container will try again in a few seconds"
      exit 1
    }
    function configure_admin_user() {
      local full_admin_list=$(gitea admin user list --admin)
      local actual_user_table=''

      # We might have distorted output due to warning logs, so we have to detect the actual user table by its headline and trim output above that line
      local regex="(.*)(ID\s+Username\s+Email\s+IsActive.*)"
      if [[ "${full_admin_list}" =~ $regex ]]; then
        actual_user_table=$(echo "${BASH_REMATCH[2]}" | tail -n+2) # tail'ing to drop the table headline
      else
        # This code block should never be reached, as long as the output table header remains the same.
        # If this code block is reached, the regex doesn't match anymore and we probably have to adjust this script.

        echo "ERROR: 'configure_admin_user' was not able to determine the current list of admin users."
        echo "       Please review the output of 'gitea admin user list --admin' shown below."
        echo "       If you think it is an issue with the Helm Chart provisioning, file an issue at https://gitea.com/gitea/helm-chart/issues."
        echo "DEBUG: Output of 'gitea admin user list --admin'"
        echo "--"
        echo "${full_admin_list}"
        echo "--"
        exit 1
      fi

      local ACCOUNT_ID=$(echo "${actual_user_table}" | grep -E "\s+${GITEA_ADMIN_USERNAME}\s+" | awk -F " " "{printf \$1}")
      if [[ -z "${ACCOUNT_ID}" ]]; then
        echo "No admin user '${GITEA_ADMIN_USERNAME}' found. Creating now..."
        gitea admin user create --admin --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}" --email "datastore@local.domain" --must-change-password=false
        echo '...created.'
      else
        echo "Admin account '${GITEA_ADMIN_USERNAME}' already exist. Running update to sync password..."
        gitea admin user change-password --username "${GITEA_ADMIN_USERNAME}" --password "${GITEA_ADMIN_PASSWORD}"
        echo '...password sync done.'
      fi
    }

    configure_admin_user

    function configure_ldap() {
        echo 'no ldap configuration... skipping.'
    }

    configure_ldap

    function configure_oauth() {
        echo 'no oauth configuration... skipping.'
    }

    configure_oauth

    echo '==== END DATASTORE CONFIGURATION ===='
---
# Source: nemo-microservices-helm-chart/charts/entity-store/templates/configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-entity-store
data:
  BASE_URL_DATASTORE: "http://nemo-data-store:3000/v1/hf"
  BASE_URL_NIM: "http://nemo-nim-proxy:8000"
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/eval-factory-init-container.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: eval-factory-init-container-template
data:
  init-container.yaml: |
    name: dataset-download-container
    image: "nvcr.io/nvidia/nemo-microservices/evaluator:25.12"
    terminationMessagePolicy: FallbackToLogsOnError
    command: download-dataset-placeholder-command
    env:
      - name: MODE
        value: standalone
      - name: NAMESPACE
        valueFrom:
          fieldRef:
            fieldPath: metadata.namespace            
      - name: POD_NAME
        valueFrom:
          fieldRef:
            fieldPath: metadata.name
      - name: CONTAINER_NAME
        value: "dataset-download-container"
      - name: DATA_STORE_URL
        value: "http://nemo-data-store:3000/v1/hf"
      - name: DATA_STORE_TOKEN
        value: ""
    volumeMounts:
      - name: jobs-storage
        mountPath: /jobs
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/eval-factory-job-template.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: eval-factory-job-template
data:
  job.yaml: |
    apiVersion: batch/v1
    kind: Job
    metadata:
      name: placeholder-job-name
      labels:
        app: eval-factory-benchmark
    spec:
      backoffLimit: 0
      ttlSecondsAfterFinished: 172800
      template:
        metadata:
          annotations:        
            sidecar.istio.io/inject: false
            proxy.istio.io/config: |
              holdApplicationUntilProxyStarts: true
        spec:
          serviceAccountName: nemo-evaluator
          imagePullSecrets:
            - name: nvcrimagepullsecret
          restartPolicy: Never
          containers:
          - name: eval-factory-container
            image: placeholder-image:placeholder-tag
            terminationMessagePolicy: FallbackToLogsOnError
            command: placeholder-command
            volumeMounts:
              - name: jobs-storage
                mountPath: /jobs                              
              - name: job-config
                mountPath: /configs
          - name: eval-results-handler-container
            image: "nvcr.io/nvidia/nemo-microservices/evaluator:25.12"
            terminationMessagePolicy: FallbackToLogsOnError
            command: results-handler-placeholder-command
            env:
              - name: MODE
                value: standalone
              - name: NAMESPACE
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.namespace            
              - name: POD_NAME
                valueFrom:
                  fieldRef:
                    fieldPath: metadata.name
              - name: CONTAINER_NAME
                value: "eval-factory-container"
              - name: DATA_STORE_URL
                value: "http://nemo-data-store:3000/v1/hf"
              - name: DATA_STORE_TOKEN
                value: ""
            volumeMounts:
              - mountPath: /jobs
                name: jobs-storage
          volumes:
          - name: jobs-storage
            emptyDir:
              sizeLimit: 10Gi
          - name: job-config
            configMap:
              name: job-config-map-placeholder
---
# Source: nemo-microservices-helm-chart/templates/platform-configmap.yaml
apiVersion: v1
kind: ConfigMap
metadata:
  name: nemo-platform-config
  labels:
    helm.sh/chart: nemo-microservices-helm-chart-25.12.0
    app.kubernetes.io/name: nemo-microservices-helm-chart
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
data:
  config.yaml: |-
    # NeMo Microservices Platform deployment configuration
    platform:
      # Base URL for the platform
      base_url: ""
      jobs_url: "http://nemo-core-api:8000"
      models_url: "http://nemo-core-api:8000"
      inference_gateway_url: "http://nemo-core-api:8000"
      datastore_url: "http://nemo-data-store:3000/v1/hf"

      # Enable/disable service account token authentication in-between services
      enable_service_account_auth: true

      # Global image pull secrets for the platform
      image_pull_secrets:
        - name: nvcrimagepullsecret
    # NeMo Microservices Platform jobs configuration
    jobs:
      schedule_interval_seconds: 10
      reconciler_interval_seconds: 

      # Executor profiles configuration
      executors:
        - profile: default
          backend: kubernetes_job
          provider: cpu
          config:
            storage:
              pvc_name: nemo-core-job-storage
              volume_permissions_image: busybox
            logging:
              enabled: true
              configmap: nemo-core-jobs-logsidecar
              image:
                repository: fluent/fluent-bit
                tag: 4.0.7
            ttl_seconds_after_finished: 10800
            image_pull_secrets:
              - name: nvcrimagepullsecret
        - profile: default
          backend: kubernetes_job
          provider: gpu
          config:
            storage:
              pvc_name: nemo-core-job-storage
              volume_permissions_image: busybox
            logging:
              enabled: true
              configmap: nemo-core-jobs-logsidecar
              image:
                repository: fluent/fluent-bit
                tag: 4.0.7
            ttl_seconds_after_finished: 10800
            image_pull_secrets:
              - name: nvcrimagepullsecret
      
      # Configure to use k8s secrets for sensitive information
      secrets:
        backend: kubernetes
        kubernetes:
          config_type: in-cluster
          namespace: default

    # NeMo Microservices Platform models configuration
    models:
      host: "0.0.0.0"
      port: 8000
      huggingface_model_puller: "nvcr.io/nvidia/nemo-microservices/nds-v2-huggingface-cli:25.12"
      controller:
        interval_seconds: 10
        model_deployment_garbage_collection_ttl_seconds: 30
        backends:
          k8s-nim-operator:
            config:
              auth_secret: ngc-api
              datastore_auth_secret: nemo-models-datastore-token
              default_nimservice_image: nvcr.io/nim/nvidia/llm-nim
              default_nimservice_image_tag: 1.14.1
              default_pvc_size: 200Gi
              default_startup_probe_grace_period_seconds: 600
              default_storage_class: ""
              huggingface_model_puller_image_pull_secret: nvcrimagepullsecret
              namespace: ""
              nim_guided_decoding_backend: outlines
              peft_refresh_interval: 30
              peft_source: http://nemo-entity-store:8000
            enabled: true
      # Configure to use k8s secrets for sensitive information
      secrets:
        backend: kubernetes
        kubernetes:
          config_type: in-cluster
          namespace: default

    # NeMo Microservices Platform inference gateway configuration
    inference_gateway:
      host: "0.0.0.0"
      port: 8000
      refresh_model_cache_interval_sec: 3
      # Configure to use k8s secrets for sensitive information
      secrets:
        backend: kubernetes
        kubernetes:
          config_type: in-cluster
          namespace: default
    # NeMo Data Designer configuration
    data_designer: 
      default_model_configs: []
      log_level: INFO
      model_provider_registry:
        default: nimproxy
        providers:
        - endpoint: http://nemo-nim-proxy:8000/v1
          name: nimproxy
      port: 8000
      preview_num_records:
        default: 10
        max: 10
      seed_dataset_source_registry:
        sources:
        - endpoint: http://nemo-data-store:3000/v1/hf
---
# Source: nemo-microservices-helm-chart/charts/core/templates/jobstorage-pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: nemo-core-job-storage
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  accessModes:
    - ReadWriteMany
  resources:
    requests:
      storage: 200Gi
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/pvc.yaml
apiVersion: v1
kind: PersistentVolumeClaim
metadata:
  name: finetuning-ms-models-pvc
spec:
  # We only want to set storageClassName when the user intentionally and explicitly specifies it in the values.
  # Otherwise, we don't want to set storageClassName at all, because it is an immutable field. It is much better
  # to just not set it, and let K8s leverage the default storage class.
  accessModes:
    - ReadWriteOnce
  resources:
    requests:
      storage: 100Gi
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/gitea/pvc.yaml
kind: PersistentVolumeClaim
apiVersion: v1
metadata:
  name: datastore-shared-storage
  namespace: default
  annotations:
    helm.sh/resource-policy: keep
  labels:
    {}
spec:
  accessModes:
    - ReadWriteOnce
  volumeMode: Filesystem
  
  resources:
    requests:
      storage: 100Gi
---
# Source: nemo-microservices-helm-chart/charts/core/templates/api-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-core-api-tokenreview
rules:
  - apiGroups: ["authentication.k8s.io"]
    resources: ["tokenreviews"]
    verbs: ["create"]
---
# Source: nemo-microservices-helm-chart/charts/deployment-management/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-deployment-management-role
  labels:
    app.kubernetes.io/name: deployment-management
    app.kubernetes.io/instance: nemo
    helm.sh/chart: deployment-management-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - "nvidia.com"
  resources:
  - nemoentityhandlers
  - nemoentityvalidators
  - nemovalidationjobs
  - nemotrainingworkloads
  - nemotrainingjobs
  - compoundainimrequests
  - compoundainimdeployments
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - "apps.nvidia.com"
  resources:
  - nimservices
  - nimcaches
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - ""
  resources:
  - apis
  - api
  - version
  - services
  - configmaps
  - secrets
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - watch
  - update
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/nemoentityvalidator-editor-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-nemo-operator-nemoentityvalidator-editor-role
  labels:
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
rules:
- apiGroups:
  - nvidia.com
  resources:
  - nemoentityvalidators
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemoentityvalidators/status
  verbs:
  - get
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/nemoentityvalidator-viewer-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-nemo-operator-nemoentityvalidator-viewer-role
  labels:
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
rules:
- apiGroups:
  - nvidia.com
  resources:
  - nemoentityvalidators
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemoentityvalidators/status
  verbs:
  - get
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/nemovalidationjob-editor-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-nemo-operator-nemovalidationjob-editor-role
  labels:
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
rules:
- apiGroups:
  - nvidia.com
  resources:
  - nemovalidationjobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemovalidationjobs/status
  verbs:
  - get
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/nemovalidationjob-viewer-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-nemo-operator-nemovalidationjob-viewer-role
  labels:
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
rules:
- apiGroups:
  - nvidia.com
  resources:
  - nemovalidationjobs
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemovalidationjobs/status
  verbs:
  - get
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/proxy-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-nemo-operator-proxy-role
  labels:
    app.kubernetes.io/component: kube-rbac-proxy
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
rules:
- apiGroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apiGroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/manager-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8s-nim-operator-role
  labels:
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  - persistentvolumeclaims
  - secrets
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - create
  - update
  - patch
  - watch
- apiGroups:
  - ""
  resources:
  - endpoints
  - pods
  - pods/log
  - pods/eviction
  - serviceaccounts
  - services
  - services/finalizers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - create
  - delete
  - get
  - list
  - watch
- apiGroups:
  - apps
  resources:
  - deployments
  - statefulsets
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemocustomizers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemocustomizers/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemocustomizers/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoguardrails
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoguardrails/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoguardrails/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemodatastores
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemodatastores/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemodatastores/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoevaluators
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoevaluators/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoevaluators/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoentitystores
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoentitystores/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nemoentitystores/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimcaches
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimcaches/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimcaches/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimpipelines
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimpipelines/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimpipelines/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimservices
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimservices/finalizers
  verbs:
  - update
- apiGroups:
  - apps.nvidia.com
  resources:
  - nimservices/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - batch
  resources:
  - jobs/status
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - config.openshift.io
  resources:
  - clusterversions
  - proxies
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - create
  - delete
  - get
  - list
- apiGroups:
  - monitoring.coreos.com
  resources:
  - prometheusrules
  - servicemonitors
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - rbac.authorization.k8s.io
  resources:
  - rolebindings
  - roles
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - route.openshift.io
  resources:
  - routes
  verbs:
  - create
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - networking.k8s.io
  resources:
  - ingresses
  verbs:
  - create
  - get
  - list
  - patch
  - update
  - watch
  - delete
- apiGroups:
  - autoscaling
  resources:
  - horizontalpodautoscalers
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - scheduling.k8s.io
  resources:
  - priorityclasses
  verbs:
  - create
  - get
  - list
  - watch
- apiGroups:
  - security.openshift.io
  resourceNames:
  - nonroot
  - anyuid
  resources:
  - securitycontextconstraints
  verbs:
  - use
- apiGroups:
  - security.openshift.io
  resources:
  - securitycontextconstraints
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - storage.k8s.io
  resources:
  - storageclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - authentication.k8s.io
  resources:
  - tokenreviews
  verbs:
  - create
- apiGroups:
  - authorization.k8s.io
  resources:
  - subjectaccessreviews
  verbs:
  - create
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs/status
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemoentityhandlers
  - nemotrainingjobs
  - nemotrainingjobs/status
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - podgroups
  - queues
  - queues/status
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - nodeinfo.volcano.sh
  resources:
  - numatopologies
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - run.ai
  resources:
  - trainingworkloads
  - runaijobs
  verbs:
  - get
  - list
  - watch
  - delete
  - patch
  - update
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/metrics-reader-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: k8s-nim-operator-metrics-reader
  labels:
    app.kubernetes.io/component: kube-rbac-proxy
    app.kubernetes.io/created-by: k8s-nim-operator
    app.kubernetes.io/part-of: k8s-nim-operator
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
rules:
- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
# Source: nemo-microservices-helm-chart/charts/nim-proxy/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nemo-nim-proxy-role
  labels:
    app.kubernetes.io/name: nim-proxy
    app.kubernetes.io/instance: nemo
    helm.sh/chart: nim-proxy-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - "apps.nvidia.com"
  resources:
  - nimservices
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - ""
  resources:
  - apis
  - api
  - version
  - services
  - configmaps
  verbs:
  - get
  - list
  - create
  - delete
  - patch
  - watch
  - update
- apiGroups:
  - ""
  resources:
  - pods
  verbs:
  - get
  - list
---
# Source: nemo-microservices-helm-chart/charts/core/templates/api-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nemo-core-api-tokenreview
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nemo-core-api-tokenreview
subjects:
  - kind: ServiceAccount
    name: nemo-core-api
    namespace: default
---
# Source: nemo-microservices-helm-chart/charts/deployment-management/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nemo-deployment-management-rolebinding
  labels:
    app.kubernetes.io/name: deployment-management
    app.kubernetes.io/instance: nemo
    helm.sh/chart: deployment-management-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nemo-deployment-management-role
subjects:
- kind: ServiceAccount
  name: nemo-deployment-management
  namespace: 'default'
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/proxy-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nemo-nemo-operator-proxy-rolebinding
  labels:
    app.kubernetes.io/component: kube-rbac-proxy
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: 'nemo-nemo-operator-proxy-role'
subjects:
- kind: ServiceAccount
  name: 'nemo-nemo-operator-controller-manager'
  namespace: 'default'
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/manager-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: k8s-nim-operator-rolebinding
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: k8s-nim-operator
    app.kubernetes.io/part-of: k8s-nim-operator
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: k8s-nim-operator-role
subjects:
- kind: ServiceAccount
  name: k8s-nim-operator
  namespace: default
---
# Source: nemo-microservices-helm-chart/charts/nim-proxy/templates/rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nemo-nim-proxy-rolebinding
  labels:
    app.kubernetes.io/name: nim-proxy
    app.kubernetes.io/instance: nemo
    helm.sh/chart: nim-proxy-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nemo-nim-proxy-role
subjects:
- kind: ServiceAccount
  name: nemo-nim-proxy
  namespace: 'default'
---
# Source: nemo-microservices-helm-chart/charts/core/templates/api-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: nemo-core-api
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["secrets"]
  verbs: ["create", "delete", "get"]
---
# Source: nemo-microservices-helm-chart/charts/core/templates/controller-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: nemo-core-controller
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups: [""]
  resources: ["pods"]
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources: ["events"]
  verbs: ["get", "list", "watch", "create"]
- apiGroups: [""]
  resources: ["pods/log"]
  verbs: ["get", "list"]
- apiGroups: ["apps"]
  resources: ["deployments"]
  verbs: ["get", "list", "watch"]
- apiGroups: ["batch"]
  resources: ["jobs"]
  verbs: ["create", "get", "list", "watch", "update", "patch", "delete"]
- apiGroups: [""]
  resources: ["persistentvolumeclaims"]
  verbs: ["get", "list", "create", "delete"]
- apiGroups: [""] 
  resources: ["configmaps"]
  verbs: ["create", "delete"]
# NIM Operator
- apiGroups: ["apps.nvidia.com"]
  resources: ["nimservices", "nimservices/status"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
- apiGroups: ["apps.nvidia.com"]
  resources: ["nimcaches", "nimcaches/status"]
  verbs: ["get", "list", "watch", "create", "update", "patch", "delete"]
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: nemo-customizer-job-creator
  namespace: default
##### !!! TODO Nick - revise rules: LLM-4038 !!! #####
rules:
- apiGroups:
  - apiextensions.k8s.io
  resources:
  - customresourcedefinitions
  verbs:
  - create
  - get
  - list
  - watch
  - delete
# Create and monitor jobs for hydrating model cache
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - batch
  resources:
  - jobs/status
  verbs:
  - get
  - list
  - watch
# End
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs
  verbs:
  - get
  - list
  - watch
  - update
  - delete
  - create
  - patch
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs/status
  verbs:
  - get
  - list
  - watch
  - update
  - delete
  - create
  - patch
- apiGroups:
  - nodeinfo.volcano.sh
  resources:
  - numatopologies
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - queues
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - podgroups
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - scheduling.incubator.k8s.io
  - scheduling.volcano.sh
  resources:
  - queues/status
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - get
  - list
  - watch
  - update
  - delete
  - create
  - patch
- apiGroups:
  - ""
  resources:
  - pods
  - pods/status
  - pods/log
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - ""
  resources:
  - pods/binding
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - ""
  resources:
  - persistentvolumes
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - namespaces
  - services
  - replicationcontrollers
  verbs:
  - list
  - watch
  - get
- apiGroups:
  - ""
  resources:
  - resourcequotas
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - ""
  resources:
  - nodes
  verbs:
  - list
- apiGroups:
  - policy
  resources:
  - poddisruptionbudgets
  verbs:
  - list
  - watch
- apiGroups:
  - scheduling.k8s.io
  resources:
  - priorityclasses
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - apps
  resources:
  - daemonsets
  - replicasets
  - statefulsets
  verbs:
  - create
  - get
  - list
  - watch
  - update
  - patch
  - bind
  - updateStatus
  - delete
- apiGroups:
  - nvidia.com
  resources:
  - nemotrainingjobs
  - nemotrainingjobs/status
  - nemoentityhandlers
  verbs:
  - get
  - list
  - watch
  - update
  - delete
  - create
  - patch
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: "nemo-evaluator-role"
rules:
  - apiGroups: [""]
    resources: ["secrets", "pods", "pods/status", "pods/log"]
    verbs: ["get", "watch", "list", "create"]
  - apiGroups: ["batch"]
    resources: ["jobs", "jobs/status"]
    verbs: ["create", "get", "list", "watch"]
  - apiGroups: [""]
    resources: ["configmaps"]
    verbs: ["create", "get"]
  - apiGroups: [""]
    resources: ["configmaps", "secrets"]
    verbs: ["delete"]
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/leader-election-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: nemo-nemo-operator-leader-election-role
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/manager-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: nemo-nemo-operator-manager-role
  namespace: default
  labels:
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
rules:
- apiGroups:
  - ""
  resources:
  - persistentvolumeclaims
  verbs:
  - create
  - delete
  - get
  - list
  - watch
- apiGroups:
  - batch
  resources:
  - jobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - batch.volcano.sh
  resources:
  - jobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - scheduling.volcano.sh
  resources:
  - podgroups
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemoentityhandlers
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemotrainingjobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemotrainingjobs/finalizers
  verbs:
  - update
- apiGroups:
  - nvidia.com
  resources:
  - nemotrainingjobs/status
  verbs:
  - get
  - patch
  - update
- apiGroups:
  - nvidia.com
  resources:
  - nemotrainingworkloads
  verbs:
  - get
  - list
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemovalidationjobs
  verbs:
  - create
  - delete
  - get
  - list
  - patch
  - update
  - watch
- apiGroups:
  - nvidia.com
  resources:
  - nemovalidationjobs/finalizers
  verbs:
  - update
- apiGroups:
  - nvidia.com
  resources:
  - nemovalidationjobs/status
  verbs:
  - get
  - patch
  - update
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/leader-election-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: Role
metadata:
  name: k8s-nim-operator-leader-election-role
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: k8s-nim-operator
    app.kubernetes.io/part-of: k8s-nim-operator
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
rules:
- apiGroups:
  - ""
  resources:
  - configmaps
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - coordination.k8s.io
  resources:
  - leases
  verbs:
  - get
  - list
  - watch
  - create
  - update
  - patch
  - delete
- apiGroups:
  - ""
  resources:
  - events
  verbs:
  - create
  - patch
---
# Source: nemo-microservices-helm-chart/charts/core/templates/api-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: nemo-core-api
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm 
subjects:
- kind: ServiceAccount
  name: nemo-core-api
  namespace: default
roleRef:
  kind: Role
  name: nemo-core-api
  apiGroup: rbac.authorization.k8s.io
---
# Source: nemo-microservices-helm-chart/charts/core/templates/controller-role.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: nemo-core-controller
  labels:
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm 
subjects:
- kind: ServiceAccount
  name: nemo-core-controller
  namespace: default
roleRef:
  kind: Role
  name: nemo-core-controller
  apiGroup: rbac.authorization.k8s.io
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/role-binding.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: nemo-customizer-job-creator-rb
  namespace: default
subjects:
- kind: ServiceAccount
  name: nemo-customizer
  namespace: default
roleRef:
  kind: Role
  name: nemo-customizer-job-creator
  apiGroup: rbac.authorization.k8s.io
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/serviceaccount.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: "nemo-evaluator-role-binding"
subjects:
- kind: ServiceAccount
  name: nemo-evaluator
roleRef:
  kind: Role
  name: "nemo-evaluator-role"
  apiGroup: rbac.authorization.k8s.io
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/leader-election-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: nemo-nemo-operator-leader-election-rolebinding
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: 'nemo-nemo-operator-leader-election-role'
subjects:
- kind: ServiceAccount
  name: 'nemo-nemo-operator-controller-manager'
  namespace: 'default'
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/manager-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: nemo-nemo-operator-manager-rolebinding
  namespace: default
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: 'nemo-nemo-operator-manager-role'
subjects:
- kind: ServiceAccount
  name: 'nemo-nemo-operator-controller-manager'
  namespace: 'default'
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/leader-election-rbac.yaml
apiVersion: rbac.authorization.k8s.io/v1
kind: RoleBinding
metadata:
  name: k8s-nim-operator-leader-election-rolebinding
  labels:
    app.kubernetes.io/component: rbac
    app.kubernetes.io/created-by: k8s-nim-operator
    app.kubernetes.io/part-of: k8s-nim-operator
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: Role
  name: k8s-nim-operator-leader-election-role
subjects:
- kind: ServiceAccount
  name: k8s-nim-operator
  namespace: 'default'
---
# Source: nemo-microservices-helm-chart/charts/core/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-jobsdb-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.2.4
    app.kubernetes.io/component: primary
  annotations:
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/core/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-jobsdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.2.4
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/core/templates/api-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-core-api
  labels:
    app.kubernetes.io/component: nemo-core-api
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/component: nemo-core-api
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/core/templates/logcollector-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-core-jobs-logcollector
  labels:
    app.kubernetes.io/component: nemo-jobs-logcollector
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  ports:
  - port: 4318
    protocol: TCP
  clusterIP: None
  selector:
    app.kubernetes.io/component: nemo-jobs-logcollector
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/opentelemetry-collector/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-opentelemetry-collector
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.93.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "0.102.1"
    app.kubernetes.io/managed-by: Helm
    
    component: standalone-collector
spec:
  type: ClusterIP
  ports:
    
    - name: jaeger-compact
      port: 6831
      targetPort: 6831
      protocol: UDP
    - name: jaeger-grpc
      port: 14250
      targetPort: 14250
      protocol: TCP
    - name: jaeger-thrift
      port: 14268
      targetPort: 14268
      protocol: TCP
    - name: otlp
      port: 4317
      targetPort: 4317
      protocol: TCP
      appProtocol: grpc
    - name: otlp-http
      port: 4318
      targetPort: 4318
      protocol: TCP
    - name: zipkin
      port: 9411
      targetPort: 9411
      protocol: TCP
  selector:
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: nemo
    component: standalone-collector
  internalTrafficPolicy: Cluster
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-customizerdb-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: customizerdb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: customizerdb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-customizerdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: customizerdb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: customizerdb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/service.yaml
apiVersion: v1
kind: Service
metadata:
    name: nemo-customizer
spec:
    type: ClusterIP
    selector:
      app.kubernetes.io/name: nemo-customizer
      app.kubernetes.io/instance: nemo
    ports:
    - name: api
      port: 8000
      protocol: TCP
      targetPort: api
    - name: internal
      port: 9009
      protocol: TCP
      targetPort: internal
---
# Source: nemo-microservices-helm-chart/charts/data-designer/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-data-designer
  labels:
    app.kubernetes.io/name: data-designer
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-designer-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: data-designer
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/data-store/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-postgresql-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/data-store/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/gitea/http-svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-data-store
  labels:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app: data-store
    version: "25.12"
  annotations:
    {}
spec:
  type: ClusterIP
  ports:
  - name: http
    port: 3000
    targetPort: 3000
  selector:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/deployment-management/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-deployment-management
  labels:
    app.kubernetes.io/name: deployment-management
    app.kubernetes.io/instance: nemo
    helm.sh/chart: deployment-management-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: 
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: deployment-management
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/entity-store/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-entity-storedb-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: entity-storedb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: entity-storedb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/entity-store/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-entity-storedb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: entity-storedb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: entity-storedb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/entity-store/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-entity-store
  labels:
    app.kubernetes.io/name: entity-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: entity-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: entity-store
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/evaluator/charts/postgresql/templates/primary/svc-headless.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-evaluatordb-hl
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: evaluatordb
    app.kubernetes.io/version: 16.2.0
    helm.sh/chart: postgresql-14.0.4
    app.kubernetes.io/component: primary
  annotations:
    # Use this annotation in addition to the actual publishNotReadyAddresses
    # field below because the annotation will stop being respected soon but the
    # field is broken in some versions of Kubernetes:
    # https://github.com/kubernetes/kubernetes/issues/58662
    service.alpha.kubernetes.io/tolerate-unready-endpoints: "true"
spec:
  type: ClusterIP
  clusterIP: None
  # We want all pods in the StatefulSet to have their addresses published for
  # the sake of the other Postgresql pods even before they're ready, since they
  # have to be able to talk to each other in order to become ready.
  publishNotReadyAddresses: true
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: evaluatordb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/evaluator/charts/postgresql/templates/primary/svc.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-evaluatordb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: evaluatordb
    app.kubernetes.io/version: 16.2.0
    helm.sh/chart: postgresql-14.0.4
    app.kubernetes.io/component: primary
spec:
  type: ClusterIP
  sessionAffinity: None
  ports:
    - name: tcp-postgresql
      port: 5432
      targetPort: tcp-postgresql
      nodePort: null
  selector:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/name: evaluatordb
    app.kubernetes.io/component: primary
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/service-internal.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-evaluator-internal
  labels:
    app.kubernetes.io/name: evaluator
    app.kubernetes.io/instance: nemo
    helm.sh/chart: evaluator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - name: internal
      port: 7332
      protocol: TCP
      targetPort: 7332
  selector:
    app.kubernetes.io/name: evaluator
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-evaluator
  labels:
    app.kubernetes.io/name: evaluator
    app.kubernetes.io/instance: nemo
    helm.sh/chart: evaluator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  ports:
    - port: 7331
      targetPort: http
      protocol: TCP
      name: http
  selector:
    app.kubernetes.io/name: evaluator
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/metrics-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-nemo-operator
  namespace: default
  labels:
    app.kubernetes.io/component: kube-rbac-proxy
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    control-plane: controller-manager
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
spec:
  type: ClusterIP
  selector:
    control-plane: controller-manager
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
  ports:
  - name: https
    port: 8443
    protocol: TCP
    targetPort: https
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/metrics-service.yaml
apiVersion: v1
kind: Service
metadata:
  name: k8s-nim-operator-metrics-service
  labels:
    app.kubernetes.io/component: kube-rbac-proxy
    app.kubernetes.io/created-by: k8s-nim-operator
    app.kubernetes.io/part-of: k8s-nim-operator
    control-plane: controller-manager
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
spec:
  type: ClusterIP
  selector:
    control-plane: controller-manager
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
  ports:
  - name: metrics
    port: 8080
    protocol: TCP
---
# Source: nemo-microservices-helm-chart/charts/nim-proxy/templates/service.yaml
apiVersion: v1
kind: Service
metadata:
  name: nemo-nim-proxy
  labels:
    app.kubernetes.io/name: nim-proxy
    app.kubernetes.io/instance: nemo
    helm.sh/chart: nim-proxy-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  type: 
  ports:
    - port: 8000
      targetPort: http
      protocol: TCP
      name: http
    - port: 8001
      targetPort: metrics
      protocol: TCP
      name: metrics
  selector:
    app.kubernetes.io/name: nim-proxy
    app.kubernetes.io/instance: nemo
---
# Source: nemo-microservices-helm-chart/charts/core/templates/api-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-core-api
  labels:
    app.kubernetes.io/component: nemo-core-api
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: nemo-core-api
      app.kubernetes.io/name: core
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/component: nemo-core-api
        app.kubernetes.io/name: core
        app.kubernetes.io/instance: nemo
        helm.sh/chart: core-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: nemo-core-api
      securityContext:
        fsGroup: 1000
      containers:
        - name: nemo-core-api
          securityContext:
            {}
          image: "nvcr.io/nvidia/nemo-microservices/nmp-core:25.12"
          imagePullPolicy: IfNotPresent
          args:
            - "infra"
            - "--target=jobs-api"            
          env:
            - name: DATABASE_DIALECT
              value: "postgresql"
            - name: DATABASE_USER
              value: nemo
            - name: DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-jobsdb
                  key: password
            - name: DATABASE_NAME
              value: "jobs"
            - name: DATABASE_HOST
              value: "nemo-jobsdb"
            - name: DATABASE_PORT
              value: "5432"
            # Entity Store database configuration (ModelEntity repository)
            - name: MODELS_DATABASE_DIALECT
              value: "postgresql"
            - name: MODELS_DATABASE_NAME
              value: "entity-store"
            - name: MODELS_DATABASE_HOST
              value: "nemo-entity-storedb"
            - name: MODELS_DATABASE_PORT
              value: "5432"
            - name: MODELS_DATABASE_USER
              value: "user"
            - name: MODELS_DATABASE_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-core-models-db-secret
                  key: password
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: http
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: http
            periodSeconds: 10
            timeoutSeconds: 5
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath:  /etc/nmp/config.yaml
              subPath: config.yaml
      volumes:
        - name: config
          configMap:
            name: nemo-platform-config
---
# Source: nemo-microservices-helm-chart/charts/core/templates/controller-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-core-controller
  labels:
    app.kubernetes.io/component: nemo-core-controller
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  replicas: 1 # Controller always runs with a single replica
  selector:
    matchLabels:
      app.kubernetes.io/component: nemo-core-controller
      app.kubernetes.io/name: core
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      annotations:
      labels:
        app.kubernetes.io/component: nemo-core-controller
        app.kubernetes.io/name: core
        app.kubernetes.io/instance: nemo
        helm.sh/chart: core-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: nemo-core-controller
      securityContext:
        fsGroup: 1000
      containers:
        - name: core-controller
          securityContext:
            {}
          image: "nvcr.io/nvidia/nemo-microservices/nmp-core:25.12"
          imagePullPolicy: IfNotPresent
          args:
            - "infra"
            - "--target=jobs-controller"            
          env:
            - name: POD_NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: NEMO_MICROSERVICES_JOBS_LAUNCHER_IMAGE
              value: "nvcr.io/nvidia/nemo-microservices/nmp-core:25.12"
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health/live
              port: http
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health/ready
              port: http
            periodSeconds: 10
            timeoutSeconds: 5
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath:  /etc/nmp/config.yaml
              subPath: config.yaml
      volumes:
        - name: config
          configMap:
            name: nemo-platform-config
---
# Source: nemo-microservices-helm-chart/charts/core/templates/logcollector-deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-core-jobs-logcollector
  labels:
    app.kubernetes.io/component: nemo-jobs-logcollector
    app.kubernetes.io/name: core
    app.kubernetes.io/instance: nemo
    helm.sh/chart: core-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
  annotations:
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/component: nemo-jobs-logcollector
      app.kubernetes.io/name: core
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        app.kubernetes.io/component: nemo-jobs-logcollector
        app.kubernetes.io/name: core
        app.kubernetes.io/instance: nemo
        helm.sh/chart: core-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: nemo-core-logcollector
      securityContext:
        fsGroup: 1000
      initContainers:
        - name: wait-for-database
          image: busybox:1.35
          command:
            - sh
            - -c
            - |
              MAX_RETRIES=30
              REQUIRED_SUCCESSES=5
              RETRY_COUNT=0
              SUCCESS_COUNT=0
              
              while [ $SUCCESS_COUNT -lt $REQUIRED_SUCCESSES ]; do
                # Use nc to check if PostgreSQL port is accepting connections
                if nc -w 2 nemo-jobsdb 5432 < /dev/null 2>/dev/null; then
                  SUCCESS_COUNT=$((SUCCESS_COUNT + 1))
                  echo "[$(date '+%Y-%m-%d %H:%M:%S')] PostgreSQL accepting connections ($SUCCESS_COUNT/$REQUIRED_SUCCESSES)"
                  if [ $SUCCESS_COUNT -lt $REQUIRED_SUCCESSES ]; then
                    sleep 3
                  fi
                else
                  RETRY_COUNT=$((RETRY_COUNT + 1))
                  SUCCESS_COUNT=0
                  if [ $RETRY_COUNT -ge $MAX_RETRIES ]; then
                    echo "[$(date '+%Y-%m-%d %H:%M:%S')] ERROR: PostgreSQL database at nemo-jobsdb:5432 is not available after $MAX_RETRIES attempts"
                    exit 1
                  fi
                  echo "[$(date '+%Y-%m-%d %H:%M:%S')] Waiting for PostgreSQL database at nemo-jobsdb:5432 (attempt $RETRY_COUNT/$MAX_RETRIES)..."
                  sleep 3
                fi
              done
              echo "[$(date '+%Y-%m-%d %H:%M:%S')] PostgreSQL database is ready (verified with $REQUIRED_SUCCESSES consecutive successful checks)"
      containers:
        - name: core-logcollector
          image: "fluent/fluent-bit:4.0.7"
          imagePullPolicy: IfNotPresent
          command: 
            - /fluent-bit/bin/fluent-bit
            - -c
            - /fluent-bit/etc/fluent-bit.yaml
          env:
            - name: DB_USER
              value: nemo
            - name: DB_PASS
              valueFrom:
                secretKeyRef:
                  name: nemo-jobsdb
                  key: password
            - name: DB_NAME
              value: "jobs"
            - name: DB_HOST
              value: "nemo-jobsdb"
            - name: DB_PORT
              value: "5432"
          volumeMounts:
          - name: config
            mountPath: /fluent-bit/etc/fluent-bit.yaml
            subPath: fluent-bit.yaml
          livenessProbe:
            failureThreshold: 3
            initialDelaySeconds: 5
            periodSeconds: 10
            tcpSocket:
              port: 4318
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /api/v1/health
              port: 2020
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
          resources:
            {}
      volumes:
      - name: config
        configMap:
          name: nemo-core-jobs-logcollector
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/opentelemetry-collector/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-opentelemetry-collector
  namespace: default
  labels:
    helm.sh/chart: opentelemetry-collector-0.93.3
    app.kubernetes.io/name: opentelemetry-collector
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "0.102.1"
    app.kubernetes.io/managed-by: Helm
    
spec:
  replicas: 1
  revisionHistoryLimit: 10
  selector:
    matchLabels:
      app.kubernetes.io/name: opentelemetry-collector
      app.kubernetes.io/instance: nemo
      component: standalone-collector
  strategy:
    type: RollingUpdate
  template:
    metadata:
      annotations:
        checksum/config: afcae313acb162abcc88620af13e7e6b31c3244422beb923c9e5a4e0b22bbb48
        
      labels:
        app.kubernetes.io/name: opentelemetry-collector
        app.kubernetes.io/instance: nemo
        component: standalone-collector
        
    spec:
      
      serviceAccountName: nemo-opentelemetry-collector
      securityContext:
        {}
      containers:
        - name: opentelemetry-collector
          args:
            - --config=/conf/relay.yaml
          securityContext:
            {}
          image: "otel/opentelemetry-collector-k8s:0.102.1"
          imagePullPolicy: IfNotPresent
          ports:
            
            - name: jaeger-compact
              containerPort: 6831
              protocol: UDP
            - name: jaeger-grpc
              containerPort: 14250
              protocol: TCP
            - name: jaeger-thrift
              containerPort: 14268
              protocol: TCP
            - name: otlp
              containerPort: 4317
              protocol: TCP
            - name: otlp-http
              containerPort: 4318
              protocol: TCP
            - name: zipkin
              containerPort: 9411
              protocol: TCP
          env:
            - name: MY_POD_IP
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: status.podIP
          livenessProbe:
            httpGet:
              path: /
              port: 13133
          readinessProbe:
            httpGet:
              path: /
              port: 13133
          volumeMounts:
            - mountPath: /conf
              name: opentelemetry-collector-configmap
      volumes:
        - name: opentelemetry-collector-configmap
          configMap:
            name: nemo-opentelemetry-collector
            items:
              - key: relay
                path: relay.yaml
      hostNetwork: false
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-customizer
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nemo-customizer
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nemo-customizer
        app.kubernetes.io/instance: nemo
        helm.sh/chart: customizer-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      serviceAccountName: nemo-customizer
      imagePullSecrets:
        
        - name: nvcrimagepullsecret
      containers:
      - name: customizer
        image: "nvcr.io/nvidia/nemo-microservices/customizer-api:25.12"
        imagePullPolicy: IfNotPresent
        env:
          - name: CONFIG_PATH
            value: /app/config/config.yaml
          - name: POSTGRES_DB_PASSWORD
            valueFrom:
              secretKeyRef:
                name: nemo-customizerdb
                key: password
          - name: POSTGRES_DB_DSN
            value: "postgresql://nemo:$(POSTGRES_DB_PASSWORD)@nemo-customizerdb:5432/finetuning"
          - name: POSTGRES_SECRET_NAME
            value: nemo-customizerdb
          - name: POSTGRES_SECRET_KEY
            value: password
          - name: "CONSOLE_LOG_LEVEL"
            value: "INFO"
          - name: WANDB_ENCRYPTION_KEY
            valueFrom:
              secretKeyRef:
                name: wandb-secret
                key: encryption_key
          - name: NGC_API_KEY
            valueFrom:
              secretKeyRef:
                name: ngc-api
                key: NGC_API_KEY
          - name: KUBERNETES_NAMESPACE
            value : default
          - name: CUSTOMIZATIONS_CALLBACK_URL
            value: "http://nemo-customizer.default.svc.cluster.local:9009"
          - name: WANDB_SECRET_NAME
            value: wandb-secret
          - name: WANDB_SECRET_KEY
            value: encryption_key
          - name: HOST_IP
            valueFrom:
              fieldRef:
                apiVersion: v1
                fieldPath: status.hostIP
          - name: OTEL_EXPORTER_OTLP_ENDPOINT
            value: "http://nemo-opentelemetry-collector:4317"
          - name: OTEL_SERVICE_NAME
            value: customizer
          - name: OTEL_TRACES_EXPORTER
            value: otlp
          - name: OTEL_METRICS_EXPORTER
            value: otlp
          - name: OTEL_LOGS_EXPORTER
            value: otlp
          - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
            value: "true"
          - name: OTEL_PYTHON_EXCLUDED_URLS
            value: health
          - name: OTEL_LOG_LEVEL
            value: "INFO"
          - name: JOB_CLEANUP_TTL_SEC
            value: "3600"
          - name: JOB_LOGS_POLLING_INTERVAL
            value: "600"
          - name: JOB_STATUS_POLLING_INTERVAL
            value: "15"
          - name: MAX_PENDING_JOB_MINUTES
            value: "30"
          - name: MAX_TRAINING_JOB_STATUS_FAILURES
            value: "10"
          - name: TRAINING_JOB_CREATION_FAILURE_SLEEP_INTERVAL
            value: "15"
        ports:
          - name: api
            containerPort: 8000
          - name: internal
            containerPort: 9009
        livenessProbe:
          httpGet:
            path: /v1/health/live
            port: api
          initialDelaySeconds: 30
          timeoutSeconds: 15
          failureThreshold: 15
        readinessProbe:
          httpGet:
            path: /v1/health/ready
            port: api
          initialDelaySeconds: 30
          timeoutSeconds: 15
          failureThreshold: 15
        volumeMounts:
        - name: config
          mountPath: "/app/config"
          readOnly: true
      volumes:
      - name: config
        configMap:
          name: nemo-customizer-config
          items:
          - key: "config.yaml"
            path: "config.yaml"
---
# Source: nemo-microservices-helm-chart/charts/data-designer/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-data-designer
  labels:
    app.kubernetes.io/name: data-designer
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-designer-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: data-designer
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        app.kubernetes.io/name: data-designer
        app.kubernetes.io/instance: nemo
        helm.sh/chart: data-designer-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: nemo-data-designer
      securityContext:
        fsGroup: 1000
      containers:
        - name: data-designer
          securityContext:
            null
          image: "nvcr.io/nvidia/nemo-microservices/data-designer:25.12"
          imagePullPolicy: IfNotPresent
          env:
            - name: NEMO_MICROSERVICES_DATA_DESIGNER_JOB_IMAGE
              value: "nvcr.io/nvidia/nemo-microservices/data-designer:25.12"
            
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 10
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 3
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 5
            periodSeconds: 5
            timeoutSeconds: 3
          resources:
            {}
          volumeMounts:
            - name: config
              mountPath:  /etc/nmp/config.yaml
              subPath: config.yaml
      volumes:
        - name: config
          configMap:
            name: nemo-platform-config
---
# Source: nemo-microservices-helm-chart/charts/data-store/templates/gitea/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-data-store
  annotations:
  labels:
    app.kubernetes.io/name: data-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: data-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app: data-store
    version: "25.12"
spec:
  replicas: 1
  strategy:
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/name: data-store
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      annotations:
        checksum/config: 37dee4c36c9cee64681539081f6f0e255c87b02798b3cf26ecd88e0e35a54a57
      labels:
        app.kubernetes.io/name: data-store
        app.kubernetes.io/instance: nemo
        helm.sh/chart: data-store-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
        app: data-store
        version: "25.12"
    spec:
      serviceAccountName: gitea
      imagePullSecrets:
        - name: nvcrimagepullsecret
      securityContext:
        fsGroup: 1000
        fsGroupChangePolicy: OnRootMismatch
      initContainers:
        - name: init-directories
          image: "nvcr.io/nvidia/nemo-microservices/datastore:25.12"
          imagePullPolicy: IfNotPresent
          command: ["/usr/sbin/init_directory_structure.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            
          securityContext:
            {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: init-app-ini
          image: "nvcr.io/nvidia/nemo-microservices/datastore:25.12"
          imagePullPolicy: IfNotPresent
          command: ["/usr/sbin/config_environment.sh"]
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA__DATABASE__PASSWD
              valueFrom:
                secretKeyRef:
                  name: nemo-postgresql
                  key: password
            
          envFrom:
            - configMapRef:
                name: nemo-data-store-setting
          volumeMounts:
            - name: config
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            - name: inline-config-sources
              mountPath: /env-to-ini-mounts/inlines/
            
          securityContext:
            {}
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
        - name: configure-datastore
          image: "nvcr.io/nvidia/nemo-microservices/datastore:25.12"
          command: ["/usr/sbin/configure_gitea.sh"]
          imagePullPolicy: IfNotPresent
          securityContext:
            runAsUser: 1000
          env:
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA__DATABASE__PASSWD
              valueFrom:
                secretKeyRef:
                  name: nemo-postgresql
                  key: password
            - name: HOME
              value: /data/gitea/git
            - name: GITEA_ADMIN_USERNAME
              value: "datastore_admin"
            - name: GITEA_ADMIN_PASSWORD
              value: "s3aJPHD9!bt6d0I"
            
          volumeMounts:
            - name: init
              mountPath: /usr/sbin
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            
          resources:
            limits: {}
            requests:
              cpu: 100m
              memory: 128Mi
      terminationGracePeriodSeconds: 60
      containers:
        - name: data-store
          image: "nvcr.io/nvidia/nemo-microservices/datastore:25.12"
          imagePullPolicy: IfNotPresent
          env:
            # SSH Port values have to be set here as well for openssh configuration
            - name: SSH_LISTEN_PORT
              value: "2222"
            - name: SSH_PORT
              value: "22"
            - name: GITEA_APP_INI
              value: /data/gitea/conf/app.ini
            - name: GITEA_CUSTOM
              value: /data/gitea
            - name: GITEA_WORK_DIR
              value: /data
            - name: GITEA_TEMP
              value: /tmp/gitea
            - name: GITEA__DATABASE__PASSWD
              valueFrom:
                secretKeyRef:
                  name: nemo-postgresql
                  key: password
            - name: TMPDIR
              value: /tmp/gitea
            - name: HOME
              value: /data/gitea/git
            
          ports:
            - name: http
              containerPort: 3000
          livenessProbe:
            failureThreshold: 20
            httpGet:
              path: /v1/health
              port: http
            initialDelaySeconds: 10
            periodSeconds: 30
            successThreshold: 1
            timeoutSeconds: 5
          readinessProbe:
            failureThreshold: 40
            httpGet:
              path: /v1/health
              port: http
            initialDelaySeconds: 30
            periodSeconds: 20
            successThreshold: 1
            timeoutSeconds: 30
          resources:
            {}
          securityContext:
            {}
          volumeMounts:
            - name: temp
              mountPath: /tmp
            - name: data
              mountPath: /data
            
      volumes:
        - name: init
          configMap:
            name: nemo-data-store-init
            defaultMode: 110
        - name: config
          configMap:
            name: nemo-data-store
            defaultMode: 110
        - name: inline-config-sources
          configMap:
            name: nemo-data-store-inline-config
        - name: temp
          emptyDir: {}
        - name: data
          persistentVolumeClaim:
            claimName: datastore-shared-storage
---
# Source: nemo-microservices-helm-chart/charts/deployment-management/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-deployment-management
  labels:
    app.kubernetes.io/name: deployment-management
    app.kubernetes.io/instance: nemo
    helm.sh/chart: deployment-management-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: deployment-management
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        app.kubernetes.io/name: deployment-management
        app.kubernetes.io/instance: nemo
        helm.sh/chart: deployment-management-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: nemo-deployment-management
      securityContext:
        {}
      containers:
        - name: deployment-management
          securityContext:
            readOnlyRootFilesystem: true
          image: "nvcr.io/nvidia/nemo-microservices/deployment-management:25.12"
          imagePullPolicy: IfNotPresent
          env:
            - name: K8S_NAMESPACE
              value: default
            - name: DEFAULT_STORAGE_CLASS
              value: 
            - name: NIMS_K8S_NAMESPACE
              value: default
            - name: NIM_NAMESPACE
              value: 
            - name: NIM_PEFT_SOURCE
              value: http://nemo-entity-store:8000
            - name: ENTITY_STORE_URL
              value: http://nemo-entity-store:8000
            - name: MODEL_SYNC_PERIOD
              value: "30"
            - name: NIM_PVC_SIZE
              value: "200Gi"
            - name: NIM_IMAGE_PULL_SECRETS
              value: nvcrimagepullsecret
            - name: DATA_STORE_URL
              value: http://nemo-data-store:3000
            - name: DATA_STORE_AUTH_SECRET
              value: nemo-deployment-management-service-ds-hf-token
            - name: NIM_CACHE_MODEL_PULLER
              value: nvcr.io/nvidia/nemo-microservices/nds-v2-huggingface-cli:25.06
            - name: NIM_CACHE_PULL_SECRET
              value: nvcrimagepullsecret
            
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: http
          readinessProbe:
            httpGet:
              path: /health
              port: http
          resources:
            {}
---
# Source: nemo-microservices-helm-chart/charts/entity-store/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-entity-store
  labels:
    app.kubernetes.io/name: entity-store
    app.kubernetes.io/instance: nemo
    helm.sh/chart: entity-store-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: entity-store
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        app.kubernetes.io/name: entity-store
        app.kubernetes.io/instance: nemo
        helm.sh/chart: entity-store-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: default
      securityContext:
        {}
      initContainers:
        - name: wait-for-postgres
          image: busybox:latest
          command:
            - 'sh'
            - '-c'
            - 'for i in $(seq 1 50); do echo "Waiting for PostgreSQL to start (attempt $i of 50)"; nc -z nemo-entity-storedb 5432 && exit 0; sleep 5; done; echo "Failed to connect after 50 attempts."; exit 1'
        - name: entity-store-db-migration
          image: "nvcr.io/nvidia/nemo-microservices/entity-store:25.12"
          workingDir: /app/services/entity-store
          env:
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-entity-storedb
                  key: password
            - name: POSTGRES_USER
              value: user
            - name: POSTGRES_HOST
              value: nemo-entity-storedb
            - name: POSTGRES_DB
              value: entity-store
            
          command: ["/app/.venv/bin/python3"]
          args: ["-m", "scripts.run_db_migration"]
      containers:
        - name: entity-store
          securityContext:
            {}
          image: "nvcr.io/nvidia/nemo-microservices/entity-store:25.12"
          imagePullPolicy: IfNotPresent
          env:
            - name: APP_VERSION
              value: ""
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-entity-storedb
                  key: password
            - name: POSTGRES_USER
              value: user
            - name: POSTGRES_HOST
              value: nemo-entity-storedb
            - name: POSTGRES_DB
              value: entity-store
            
          envFrom:
          - configMapRef:
              name: nemo-entity-store
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
          livenessProbe:
            failureThreshold: 10
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 3
            periodSeconds: 10
            timeoutSeconds: 20
          readinessProbe:
            failureThreshold: 20
            httpGet:
              path: /health
              port: http
            initialDelaySeconds: 10
            periodSeconds: 10
            timeoutSeconds: 20
          resources:
            {}
---
# Source: nemo-microservices-helm-chart/charts/evaluator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-evaluator
  labels:
    app.kubernetes.io/name: evaluator
    app.kubernetes.io/instance: nemo
    helm.sh/chart: evaluator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: evaluator
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        app.kubernetes.io/name: evaluator
        app.kubernetes.io/instance: nemo
        helm.sh/chart: evaluator-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: nemo-evaluator
      securityContext:
        {}
      initContainers:
        - name: wait-for-postgres
          image: busybox:latest
          command:
            - 'sh'
            - '-c'
            - 'for i in $(seq 1 50); do echo "Waiting for PostgreSQL to start (attempt $i of 50)"; nc -z nemo-evaluatordb 5432 && exit 0; sleep 5; done; echo "Failed to connect after 50 attempts."; exit 1'
        
        - name: evaluator-db-migration
          image:  "nvcr.io/nvidia/nemo-microservices/evaluator:25.12"
          imagePullPolicy: IfNotPresent
          env:
            - name: MODE
              value: standalone
            - name: POSTGRES_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-evaluatordb
                  key: password
            - name: POSTGRES_URI
              value: "postgresql://nemo:$(POSTGRES_DB_PASSWORD)@nemo-evaluatordb:5432/evaluation"
            
          command:
            - "/bin/sh"
            - "-c"
            - "/app/scripts/run-db-migration.sh"
          securityContext:
            runAsUser: 0
          resources:
            limits:
              cpu: 1
              memory: 1Gi
      containers:
        - name: evaluator
          securityContext:
            {}
          image: "nvcr.io/nvidia/nemo-microservices/evaluator:25.12"
          imagePullPolicy: IfNotPresent
          env:
            - name: NAMESPACE
              valueFrom:
                fieldRef:
                  fieldPath: metadata.namespace
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: EVALUATOR_HOST
              value: 0.0.0.0
            - name: EVALUATOR_PORT
              value: "7331"
            - name: POSTGRES_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-evaluatordb
                  key: password
            - name: POSTGRES_URI
              value: "postgresql://nemo:$(POSTGRES_DB_PASSWORD)@nemo-evaluatordb:5432/evaluation"
            - name: MILVUS_URL
              value: ""
            - name: EVALUATOR_IMAGE
              value: "nvcr.io/nvidia/nemo-microservices/evaluator:25.12"
            - name: EVALUATIONS_CALLBACK_URL
              value: "http://nemo-evaluator-internal.default.svc.cluster.local:7332"
            - name: DATA_STORE_URL
              value: "http://nemo-data-store:3000/v1/hf"
            - name: NEMO_MICROSERVICES_DATASTORE_URL
              value: "http://nemo-data-store:3000/v1/hf"
            - name: ENTITY_STORE_URL
              value: "http://nemo-entity-store:8000"
            - name: NEMO_MICROSERVICES_JOBS_URL
              value: "http://nemo-core-api:8000"
            - name: NEMO_MICROSERVICES_ENABLE_SERVICE_ACCOUNT_AUTH
              value: "True"
            - name: NIM_PROXY_URL
              value: "http://nemo-nim-proxy:8000"
            - name: EVAL_JOB_MONITORING_INTERVAL
              value: "5"
            - name: EVAL_JOB_MONITORING_TIMEOUT
              value: "36000"
            

            # OpenTelemetry
            - name: OTEL_TRACES_EXPORTER
              value: none
            - name: OTEL_METRICS_EXPORTER
              value: none
            - name: OTEL_LOGS_EXPORTER
              value: none
            - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
              value: "false"
            - name: LOG_HANDLERS
              value: console
            - name: CONSOLE_LOG_LEVEL
              value: "INFO"
            - name: EVAL_LOG_LEVEL
              value: "INFO"
          ports:
            - name: http
              containerPort: 7331
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: http
          readinessProbe:
            httpGet:
              path: /health
              port: http
          resources:
            {}

        # Internal server for callbacks
        - name: evaluator-internal
          securityContext:
            {}
          image: "nvcr.io/nvidia/nemo-microservices/evaluator:25.12"
          imagePullPolicy: IfNotPresent
          command: ["opentelemetry-instrument", "python", "-m", "evaluator.internal_server"]
          env:
            - name: HOST_IP
              valueFrom:
                fieldRef:
                  fieldPath: status.hostIP
            - name: EVALUATOR_PORT_INTERNAL
              value: "7332"
            - name: POSTGRES_DB_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-evaluatordb
                  key: password
            - name: POSTGRES_URI
              value: "postgresql://nemo:$(POSTGRES_DB_PASSWORD)@nemo-evaluatordb:5432/evaluation"
            
            # OpenTelemetry
            - name: OTEL_TRACES_EXPORTER
              value: none
            - name: OTEL_METRICS_EXPORTER
              value: none
            - name: OTEL_LOGS_EXPORTER
              value: none
            - name: OTEL_PYTHON_LOGGING_AUTO_INSTRUMENTATION_ENABLED
              value: "false"
            - name: LOG_HANDLERS
              value: console
            - name: CONSOLE_LOG_LEVEL
              value: "INFO"
            - name: EVAL_LOG_LEVEL
              value: "INFO"
          ports:
            - name: http-internal
              containerPort: 7332
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: http-internal
          readinessProbe:
            httpGet:
              path: /health
              port: http-internal
          resources:
            {}
---
# Source: nemo-microservices-helm-chart/charts/nemo-operator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-nemo-operator-controller-manager
  labels:
    app.kubernetes.io/component: manager
    app.kubernetes.io/created-by: nemo-kubernetes-operator
    app.kubernetes.io/part-of: nemo-kubernetes-operator
    control-plane: controller-manager
    helm.sh/chart: nemo-operator-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: nemo-operator
    app.kubernetes.io/instance: nemo
spec:
  replicas: 1
  selector:
    matchLabels:
      control-plane: controller-manager
      app.kubernetes.io/name: nemo-operator
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        control-plane: controller-manager
        app.kubernetes.io/name: nemo-operator
        app.kubernetes.io/instance: nemo
      annotations:
        kubectl.kubernetes.io/default-container: manager
    spec:
      containers:
      - args:
        - --secure-listen-address=0.0.0.0:8443
        - --upstream=http://127.0.0.1:8080/
        - --logtostderr=true
        - --v=0
        env:
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        image: "gcr.io/kubebuilder/kube-rbac-proxy:v0.15.0"
        name: kube-rbac-proxy
        ports:
        - containerPort: 8443
          name: https
          protocol: TCP
        resources:
          limits:
            cpu: 500m
            memory: 128Mi
          requests:
            cpu: 5m
            memory: 64Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
      - args:
          - --health-probe-bind-address=:8081
          - --metrics-bind-address=127.0.0.1:8080
          - --leader-elect
          - --leader-election-id=nemo.nko.nvidia.com
          - --scheduler=volcano
          - --restrictedNamespace=default
        command:
        - /manager
        env:
        - name: KUBERNETES_CLUSTER_DOMAIN
          value: "cluster.local"
        
        image: nvcr.io/nvidia/nemo-microservices/nemo-operator:25.12
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 15
          periodSeconds: 20
        name: manager
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8081
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          limits:
            cpu: 1024m
            memory: 2Gi
          requests:
            cpu: 512m
            memory: 1Gi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
      imagePullSecrets:
        - name: nvcrimagepullsecret
      securityContext:
        runAsNonRoot: true
      serviceAccountName: nemo-nemo-operator-controller-manager
      terminationGracePeriodSeconds: 10
---
# Source: nemo-microservices-helm-chart/charts/nim-operator/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-nim-operator
  labels:
    app.kubernetes.io/component: manager
    app.kubernetes.io/created-by: k8s-nim-operator
    app.kubernetes.io/part-of: k8s-nim-operator
    control-plane: controller-manager
    helm.sh/chart: nim-operator-2.0.2
    app.kubernetes.io/name: nim-operator
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/version: "2.0.2"
    app.kubernetes.io/managed-by: Helm
  annotations:
    {}
spec:
  replicas: 1
  selector:
    matchLabels:
      control-plane: controller-manager
      app.kubernetes.io/name: nim-operator
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        control-plane: controller-manager
        app.kubernetes.io/name: nim-operator
        app.kubernetes.io/instance: nemo
      annotations:
        kubectl.kubernetes.io/default-container: manager
    spec:
      containers:
      - args:
        - --health-probe-bind-address=:8081
        - --metrics-bind-address=:8080
        - --leader-elect
        command:
        - /manager
        image: nvcr.io/nvidia/cloud-native/k8s-nim-operator:v2.0.2
        imagePullPolicy: Always
        env:
          - name: WATCH_NAMESPACE
            value: ""
          - name: OPERATOR_NAMESPACE
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8081
          initialDelaySeconds: 15
          periodSeconds: 20
        name: manager
        readinessProbe:
          httpGet:
            path: /readyz
            port: 8081
          initialDelaySeconds: 5
          periodSeconds: 10
        resources:
          limits:
            cpu: "1"
            memory: 256Mi
          requests:
            cpu: 500m
            memory: 128Mi
        securityContext:
          allowPrivilegeEscalation: false
          capabilities:
            drop:
            - ALL
      imagePullSecrets:
      securityContext:
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      serviceAccountName: k8s-nim-operator
      terminationGracePeriodSeconds: 10
      affinity:
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - preference:
              matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: In
                values:
                - ""
            weight: 1
      tolerations:
        - effect: NoSchedule
          key: node-role.kubernetes.io/control-plane
          operator: Equal
          value: ""
---
# Source: nemo-microservices-helm-chart/charts/nim-proxy/templates/deployment.yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: nemo-nim-proxy
  labels:
    app.kubernetes.io/name: nim-proxy
    app.kubernetes.io/instance: nemo
    helm.sh/chart: nim-proxy-25.12.0
    app.kubernetes.io/version: "25.12"
    app.kubernetes.io/managed-by: Helm
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nim-proxy
      app.kubernetes.io/instance: nemo
  template:
    metadata:
      labels:
        app.kubernetes.io/name: nim-proxy
        app.kubernetes.io/instance: nemo
        helm.sh/chart: nim-proxy-25.12.0
        app.kubernetes.io/version: "25.12"
        app.kubernetes.io/managed-by: Helm
    spec:
      imagePullSecrets:
        - name: nvcrimagepullsecret
      serviceAccountName: nemo-nim-proxy
      securityContext:
        {}
      containers:
        - name: nim-proxy
          securityContext:
            readOnlyRootFilesystem: true
          image: "nvcr.io/nvidia/nemo-microservices/nim-proxy:25.12"
          imagePullPolicy: IfNotPresent
          env:
            - name: K8S_NAMESPACE
              value: default
            - name: NIM_CONFIGS_NAMESPACE
              value: default
            - name: NIM_NAMESPACE
              value: 
            
          ports:
            - name: http
              containerPort: 8000
              protocol: TCP
            - name: metrics
              containerPort: 8001
              protocol: TCP
          livenessProbe:
            httpGet:
              path: /health
              port: http
          readinessProbe:
            httpGet:
              path: /health
              port: http
          resources:
            {}
---
# Source: nemo-microservices-helm-chart/charts/core/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nemo-jobsdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: jobsdb
    app.kubernetes.io/version: 17.2.0
    helm.sh/chart: postgresql-16.2.4
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: nemo-jobsdb-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nemo
      app.kubernetes.io/name: jobsdb
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: nemo-jobsdb
      labels:
        app.kubernetes.io/instance: nemo
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: jobsdb
        app.kubernetes.io/version: 17.2.0
        helm.sh/chart: postgresql-16.2.4
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: jobs-postgresql
      imagePullSecrets:
        - name: nvcrimagepullsecret
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: nemo
                    app.kubernetes.io/name: jobsdb
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnamilegacy/postgresql:17.2.0-debian-12-r1
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: true
            runAsGroup: 1001
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "nemo"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-jobsdb
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-jobsdb
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "jobs"
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "nemo" -d "dbname=jobs" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "nemo" -d "dbname=jobs" -h 127.0.0.1 -p 5432
          resources:
            limits:
              cpu: 150m
              ephemeral-storage: 2Gi
              memory: 192Mi
            requests:
              cpu: 100m
              ephemeral-storage: 50Mi
              memory: 128Mi
          volumeMounts:
            - name: empty-dir
              mountPath: /tmp
              subPath: tmp-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/conf
              subPath: app-conf-dir
            - name: empty-dir
              mountPath: /opt/bitnami/postgresql/tmp
              subPath: app-tmp-dir
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: empty-dir
          emptyDir: {}
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: nemo-microservices-helm-chart/charts/customizer/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nemo-customizerdb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: customizerdb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: nemo-customizerdb-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nemo
      app.kubernetes.io/name: customizerdb
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: nemo-customizerdb
      labels:
        app.kubernetes.io/instance: nemo
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: customizerdb
        app.kubernetes.io/version: 16.1.0
        helm.sh/chart: postgresql-13.3.1
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: customizer-postgresql
      imagePullSecrets:
        - name: nvcrimagepullsecret
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: nemo
                    app.kubernetes.io/name: customizerdb
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnamilegacy/postgresql:16.1.0-debian-11-r20
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "nemo"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-customizerdb
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-customizerdb
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "finetuning"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "nemo" -d "dbname=finetuning" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "nemo" -d "dbname=finetuning" -h 127.0.0.1 -p 5432
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: nemo-microservices-helm-chart/charts/data-store/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nemo-postgresql
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: postgresql
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: nemo-postgresql-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nemo
      app.kubernetes.io/name: postgresql
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: nemo-postgresql
      labels:
        app.kubernetes.io/instance: nemo
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: postgresql
        app.kubernetes.io/version: 16.1.0
        helm.sh/chart: postgresql-13.3.1
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: nemo-postgresql
      imagePullSecrets:
        - name: nvcrimagepullsecret
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: nemo
                    app.kubernetes.io/name: postgresql
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnamilegacy/postgresql:16.1.0-debian-11-r20
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "datastore"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-postgresql
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-postgresql
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "datastore"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "datastore" -d "dbname=datastore" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "datastore" -d "dbname=datastore" -h 127.0.0.1 -p 5432
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "10Gi"
---
# Source: nemo-microservices-helm-chart/charts/entity-store/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nemo-entity-storedb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: entity-storedb
    app.kubernetes.io/version: 16.1.0
    helm.sh/chart: postgresql-13.3.1
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: nemo-entity-storedb-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nemo
      app.kubernetes.io/name: entity-storedb
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: nemo-entity-storedb
      labels:
        app.kubernetes.io/instance: nemo
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: entity-storedb
        app.kubernetes.io/version: 16.1.0
        helm.sh/chart: postgresql-13.3.1
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: entity-store-postgresql
      imagePullSecrets:
        - name: nvcrimagepullsecret
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: nemo
                    app.kubernetes.io/name: entity-storedb
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnamilegacy/postgresql:16.1.0-debian-11-r20
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seLinuxOptions: {}
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "user"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-entity-storedb
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-entity-storedb
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "entity-store"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "user" -d "dbname=entity-store" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "user" -d "dbname=entity-store" -h 127.0.0.1 -p 5432
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: nemo-microservices-helm-chart/charts/evaluator/charts/postgresql/templates/primary/statefulset.yaml
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: nemo-evaluatordb
  namespace: "default"
  labels:
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
    app.kubernetes.io/name: evaluatordb
    app.kubernetes.io/version: 16.2.0
    helm.sh/chart: postgresql-14.0.4
    app.kubernetes.io/component: primary
spec:
  replicas: 1
  serviceName: nemo-evaluatordb-hl
  updateStrategy:
    rollingUpdate: {}
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nemo
      app.kubernetes.io/name: evaluatordb
      app.kubernetes.io/component: primary
  template:
    metadata:
      name: nemo-evaluatordb
      labels:
        app.kubernetes.io/instance: nemo
        app.kubernetes.io/managed-by: Helm
        app.kubernetes.io/name: evaluatordb
        app.kubernetes.io/version: 16.2.0
        helm.sh/chart: postgresql-14.0.4
        app.kubernetes.io/component: primary
    spec:
      serviceAccountName: evaluator-postgresql
      imagePullSecrets:
        - name: nvcrimagepullsecret
      automountServiceAccountToken: false
      affinity:
        podAffinity:
          
        podAntiAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
            - podAffinityTerm:
                labelSelector:
                  matchLabels:
                    app.kubernetes.io/instance: nemo
                    app.kubernetes.io/name: evaluatordb
                    app.kubernetes.io/component: primary
                topologyKey: kubernetes.io/hostname
              weight: 1
        nodeAffinity:
          
      securityContext:
        fsGroup: 1001
        fsGroupChangePolicy: Always
        supplementalGroups: []
        sysctls: []
      hostNetwork: false
      hostIPC: false
      containers:
        - name: postgresql
          image: docker.io/bitnamilegacy/postgresql:16.2.0-debian-11-r1
          imagePullPolicy: "IfNotPresent"
          securityContext:
            allowPrivilegeEscalation: false
            capabilities:
              drop:
              - ALL
            privileged: false
            readOnlyRootFilesystem: false
            runAsNonRoot: true
            runAsUser: 1001
            seccompProfile:
              type: RuntimeDefault
          env:
            - name: BITNAMI_DEBUG
              value: "false"
            - name: POSTGRESQL_PORT_NUMBER
              value: "5432"
            - name: POSTGRESQL_VOLUME_DIR
              value: "/bitnami/postgresql"
            - name: PGDATA
              value: "/bitnami/postgresql/data"
            # Authentication
            - name: POSTGRES_USER
              value: "nemo"
            - name: POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-evaluatordb
                  key: password
            - name: POSTGRES_POSTGRES_PASSWORD
              valueFrom:
                secretKeyRef:
                  name: nemo-evaluatordb
                  key: postgres-password
            - name: POSTGRES_DATABASE
              value: "evaluation"
            # Replication
            # Initdb
            # Standby
            # LDAP
            - name: POSTGRESQL_ENABLE_LDAP
              value: "no"
            # TLS
            - name: POSTGRESQL_ENABLE_TLS
              value: "no"
            # Audit
            - name: POSTGRESQL_LOG_HOSTNAME
              value: "false"
            - name: POSTGRESQL_LOG_CONNECTIONS
              value: "false"
            - name: POSTGRESQL_LOG_DISCONNECTIONS
              value: "false"
            - name: POSTGRESQL_PGAUDIT_LOG_CATALOG
              value: "off"
            # Others
            - name: POSTGRESQL_CLIENT_MIN_MESSAGES
              value: "error"
            - name: POSTGRESQL_SHARED_PRELOAD_LIBRARIES
              value: "pgaudit"
          ports:
            - name: tcp-postgresql
              containerPort: 5432
          livenessProbe:
            failureThreshold: 6
            initialDelaySeconds: 30
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - exec pg_isready -U "nemo" -d "dbname=evaluation" -h 127.0.0.1 -p 5432
          readinessProbe:
            failureThreshold: 6
            initialDelaySeconds: 5
            periodSeconds: 10
            successThreshold: 1
            timeoutSeconds: 5
            exec:
              command:
                - /bin/sh
                - -c
                - -e
                - |
                  exec pg_isready -U "nemo" -d "dbname=evaluation" -h 127.0.0.1 -p 5432
          resources:
            limits: {}
            requests:
              cpu: 250m
              memory: 256Mi
          volumeMounts:
            - name: dshm
              mountPath: /dev/shm
            - name: data
              mountPath: /bitnami/postgresql
      volumes:
        - name: dshm
          emptyDir:
            medium: Memory
  volumeClaimTemplates:
    - apiVersion: v1
      kind: PersistentVolumeClaim
      metadata:
        name: data
      spec:
        accessModes:
          - "ReadWriteOnce"
        resources:
          requests:
            storage: "8Gi"
---
# Source: nemo-microservices-helm-chart/templates/ingress.yaml
apiVersion: networking.k8s.io/v1
kind: Ingress
metadata:
  name: nemo-microservices-helm-chart
  labels:
    helm.sh/chart: nemo-microservices-helm-chart-25.12.0
    app.kubernetes.io/name: nemo-microservices-helm-chart
    app.kubernetes.io/instance: nemo
    app.kubernetes.io/managed-by: Helm
  annotations:
    ingress.kubernetes.io/proxy-body-size: 50g
    nginx.ingress.kubernetes.io/proxy-body-size: 50g
spec:
  rules:
    -
      host: "data-store.test"
      http:
        paths:
          - path: /
            pathType: Prefix
            backend:
              service:
                name: nemo-data-store
                port:
                  number: 3000
    -
      http:
        paths:
          - path: /v1/namespaces
            pathType: Prefix
            backend:
              service:
                name: nemo-entity-store
                port:
                  number: 8000
          - path: /v1/projects
            pathType: Prefix
            backend:
              service:
                name: nemo-entity-store
                port:
                  number: 8000
          - path: /v1/datasets
            pathType: Prefix
            backend:
              service:
                name: nemo-entity-store
                port:
                  number: 8000
          - path: /v1/repos
            pathType: Prefix
            backend:
              service:
                name: nemo-entity-store
                port:
                  number: 8000
          - path: /v1/models
            pathType: Prefix
            backend:
              service:
                name: nemo-entity-store
                port:
                  number: 8000
          - path: /v1/customization
            pathType: Prefix
            backend:
              service:
                name: nemo-customizer
                port:
                  number: 8000
          - path: /v1/evaluation
            pathType: Prefix
            backend:
              service:
                name: nemo-evaluator
                port:
                  number: 7331
          - path: /v2/evaluation
            pathType: Prefix
            backend:
              service:
                name: nemo-evaluator
                port:
                  number: 7331
          - path: /v1/guardrail
            pathType: Prefix
            backend:
              service:
                name: nemo-guardrails
                port:
                  number: 7331
          - path: /v1/deployment
            pathType: Prefix
            backend:
              service:
                name: nemo-deployment-management
                port:
                  number: 8000
          - path: /v1/data-designer
            pathType: Prefix
            backend:
              service:
                name: nemo-data-designer
                port:
                  number: 8000
          - path: /v1beta1/audit
            pathType: Prefix
            backend:
              service:
                name: nemo-auditor
                port:
                  number: 5000
          - path: /v1beta1/safe-synthesizer
            pathType: Prefix
            backend:
              service:
                name: nemo-safe-synthesizer
                port:
                  number: 8000
          - path: /v1/jobs
            pathType: Prefix
            backend:
              service:
                name: nemo-core-api
                port:
                  number: 8000
          - path: /v2/inference/gateway
            pathType: Prefix
            backend:
              service:
                name: nemo-core-api
                port:
                  number: 8000
          - path: /v2/inference
            pathType: Prefix
            backend:
              service:
                name: nemo-core-api
                port:
                  number: 8000
          - path: /v2/models
            pathType: Prefix
            backend:
              service:
                name: nemo-core-api
                port:
                  number: 8000
          - path: /v1/intake
            pathType: Prefix
            backend:
              service:
                name: nemo-intake
                port:
                  number: 8000
          - path: /studio
            pathType: Prefix
            backend:
              service:
                name: nemo-studio
                port:
                  number: 3000
    -
      host: "nim.test"
      http:
        paths:
          - path: /v1/completions
            pathType: Prefix
            backend:
              service:
                name: nemo-nim-proxy
                port:
                  number: 8000
          - path: /v1/chat
            pathType: Prefix
            backend:
              service:
                name: nemo-nim-proxy
                port:
                  number: 8000
          - path: /v1/embeddings
            pathType: Prefix
            backend:
              service:
                name: nemo-nim-proxy
                port:
                  number: 8000
          - path: /v1/classify
            pathType: Prefix
            backend:
              service:
                name: nemo-nim-proxy
                port:
                  number: 8000
          - path: /v1/models
            pathType: Prefix
            backend:
              service:
                name: nemo-nim-proxy
                port:
                  number: 8000
---
# Source: nemo-microservices-helm-chart/charts/customizer/templates/finetuning/role.yaml
# Please edit the object below. Lines beginning with a '#' will be ignored,
# and an empty file will abort the edit. If an error occurs while saving this file will be
# reopened with the relevant failures.
#

